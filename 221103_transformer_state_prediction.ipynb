{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a61cb1b-16ae-4125-937d-5e687507c22f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence,pad_packed_sequence\n",
    "import torch.nn.init as weight_init\n",
    "from torch.optim import Adam\n",
    "import scipy\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from ai_clinician.modeling.models.komorowski_model import *\n",
    "from ai_clinician.modeling.models.dqn import *\n",
    "from ai_clinician.modeling.models.common import *\n",
    "from ai_clinician.modeling.normalization import *\n",
    "from ai_clinician.modeling.columns import C_OUTCOME\n",
    "from ai_clinician.preprocessing.utils import load_csv\n",
    "from ai_clinician.preprocessing.columns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70aa2f51-8c09-4e47-a784-6f2031a7df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/high_res_221102\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45962b3e-18b2-4833-93af-46489067a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319553\n"
     ]
    }
   ],
   "source": [
    "dataset = load_csv(os.path.join(data_dir, \"mimic_dataset.csv\"))\n",
    "sepsis_cohort = load_csv(os.path.join(data_dir, \"sepsis_cohort.csv\"))\n",
    "dataset = dataset[dataset[C_ICUSTAYID].isin(sepsis_cohort[C_ICUSTAYID].unique())]\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ece94622-60e9-4c9a-a886-3f9da45d0dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199930        NaN\n",
       "199931    20.0000\n",
       "199932    20.5714\n",
       "199933    24.0000\n",
       "199934    24.0000\n",
       "199935    24.0000\n",
       "199936    24.0000\n",
       "199937        NaN\n",
       "199938        NaN\n",
       "199939        NaN\n",
       "199940    30.0000\n",
       "199941    30.0000\n",
       "199942    30.0000\n",
       "199943        NaN\n",
       "Name: HCO3, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset[pd.isna(dataset[C_HCO3]) & dataset[C_ICUSTAYID].isin(train_ids)].sample(n=1)[C_ICUSTAYID]\n",
    "dataset[dataset[C_ICUSTAYID] == 35732616][C_HCO3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb0c2151-3a32-484a-945f-32fb3f50e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_state_value(g):\n",
    "    return np.concatenate([g[1:], np.array([pd.NA])])\n",
    "\n",
    "next_fluid_action = dataset[C_INPUT_STEP].groupby(dataset[C_ICUSTAYID]).transform(next_state_value)\n",
    "next_vaso_action = dataset[C_MAX_DOSE_VASO].groupby(dataset[C_ICUSTAYID]).transform(next_state_value)\n",
    "availability_mask = (dataset[C_WEIGHT] > 50) & (dataset[C_AGE] > 18) # (~pd.isna(next_fluid_action)) & \n",
    "\n",
    "next_fluid_action = (next_fluid_action / np.where(dataset[C_WEIGHT] == 0, 1, dataset[C_WEIGHT])) * 2 # 30 min interval -> 1 hour\n",
    "dataset = dataset[availability_mask]\n",
    "next_fluid_action = next_fluid_action[availability_mask]\n",
    "next_vaso_action = next_vaso_action[availability_mask]\n",
    "\n",
    "availability_mask = dataset[C_BLOC].groupby(dataset[C_ICUSTAYID]).transform(\"count\") > 1\n",
    "dataset = dataset[availability_mask]\n",
    "next_fluid_action = next_fluid_action[availability_mask]\n",
    "next_vaso_action = next_vaso_action[availability_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4af4eaa8-7afd-4f24-9a8d-3a5c4bec42a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16572 1842 4604\n"
     ]
    }
   ],
   "source": [
    "icuuniqueids = dataset[C_ICUSTAYID].unique()\n",
    "train_ids, test_ids = train_test_split(icuuniqueids, train_size=0.8)\n",
    "train_ids, val_ids = train_test_split(train_ids, train_size=0.9)\n",
    "print(len(train_ids), len(val_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2714d408-8532-48f7-986c-d84e3611670b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bloc', 'icustayid', 'timestep', 'gender', 'age', 'elixhauser',\n",
       "       're_admission', 'died_in_hosp', 'died_within_48h_of_out_time',\n",
       "       'morta_90', 'delay_end_of_record_and_discharge_or_death', 'Height_cm',\n",
       "       'Weight_kg', 'GCS', 'RASS', 'HR', 'SysBP', 'MeanBP', 'DiaBP', 'RR',\n",
       "       'SpO2', 'Temp_C', 'Temp_F', 'CVP', 'PAPsys', 'PAPmean', 'PAPdia', 'CI',\n",
       "       'SVR', 'Interface', 'FiO2_100', 'FiO2_1', 'O2flow', 'PEEP',\n",
       "       'TidalVolume', 'MinuteVentil', 'PAWmean', 'PAWpeak', 'PAWplateau',\n",
       "       'Potassium', 'Sodium', 'Chloride', 'Glucose', 'BUN', 'Creatinine',\n",
       "       'Magnesium', 'Calcium', 'Ionised_Ca', 'CO2_mEqL', 'SGOT', 'SGPT',\n",
       "       'Total_bili', 'Direct_bili', 'Total_protein', 'Albumin', 'Troponin',\n",
       "       'CRP', 'Hb', 'Ht', 'RBC_count', 'WBC_count', 'Platelets_count', 'PTT',\n",
       "       'PT', 'ACT', 'INR', 'Arterial_pH', 'paO2', 'paCO2', 'Arterial_BE',\n",
       "       'Arterial_lactate', 'HCO3', 'ETCO2', 'SvO2', 'mechvent', 'extubated',\n",
       "       'input_total', 'input_step', 'output_total', 'output_step',\n",
       "       'cumulated_balance', 'median_dose_vaso', 'max_dose_vaso', 'Shock_Index',\n",
       "       'PaO2_FiO2', 'SOFA', 'SIRS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4be09bb5-71fc-45dd-9592-a5af4e7a5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_IS_COLUMNS = [C_GENDER, C_MECHVENT, C_MAX_DOSE_VASO, C_RE_ADMISSION]\n",
    "NORM_COLUMNS = [C_AGE, C_ELIXHAUSER, C_HEIGHT, C_WEIGHT, C_GCS, \n",
    "                C_HR, C_SYSBP, C_MEANBP, C_DIABP, C_RR, \n",
    "                C_TEMP_C, C_FIO2_1, C_PAPSYS, C_PAPMEAN, C_PAPDIA, \n",
    "                C_CI, C_IONISED_CA, C_CO2_MEQL, C_TOTAL_PROTEIN,  # there's no SVR data so excluding C_SVR\n",
    "                C_ALBUMIN, C_TROPONIN, C_CRP, C_ACT,\n",
    "                C_POTASSIUM, C_SODIUM, C_CHLORIDE, C_GLUCOSE, C_MAGNESIUM, C_CALCIUM,\n",
    "                C_HB, C_HT, C_RBC_COUNT, C_WBC_COUNT, C_PLATELETS_COUNT, C_PTT, \n",
    "                C_PT, C_ARTERIAL_PH, C_PAO2, C_PACO2, C_ARTERIAL_BE, C_HCO3, \n",
    "                C_ETCO2, C_SVO2, C_ARTERIAL_LACTATE, C_SOFA, C_SIRS]\n",
    "LOG_NORM_COLUMNS = [C_SPO2, C_BUN, C_CREATININE, C_SGOT, C_SGPT, \n",
    "                    C_TOTAL_BILI, C_DIRECT_BILI, C_INR, C_INPUT_TOTAL, C_INPUT_STEP, \n",
    "                    C_OUTPUT_TOTAL, C_OUTPUT_STEP, C_SHOCK_INDEX, C_PAO2_FIO2, C_CUMULATED_BALANCE]\n",
    "\n",
    "ALL_FEATURE_COLUMNS = AS_IS_COLUMNS + NORM_COLUMNS + LOG_NORM_COLUMNS\n",
    "\n",
    "class DataNormalization:\n",
    "    \"\"\"\n",
    "    Handles all normalization of MIMIC data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, training_data, scaler=None):\n",
    "        if scaler is not None:\n",
    "            self.scaler = scaler\n",
    "        else:\n",
    "            self.scaler = StandardScaler()\n",
    "            scores_to_norm = np.hstack([training_data[NORM_COLUMNS].astype(np.float64).values,\n",
    "                                        self._clip_and_log_transform(training_data[LOG_NORM_COLUMNS])])\n",
    "            self.scaler.fit(scores_to_norm)\n",
    "\n",
    "    def _preprocess_normalized_data(self, MIMICzs):\n",
    "        \"\"\"Performs ad-hoc normalization on the normalized variables.\"\"\"\n",
    "        \n",
    "        # MIMICzs[pd.isna(MIMICzs)] = 0\n",
    "        MIMICzs[C_MAX_DOSE_VASO] = np.log(MIMICzs[C_MAX_DOSE_VASO] + 6)   # MAX DOSE NORAD \n",
    "        # MIMICzs[C_INPUT_STEP] = 2 * MIMICzs[C_INPUT_STEP]   # increase weight of this variable\n",
    "        return MIMICzs\n",
    "\n",
    "    def _clip_and_log_transform(self, data, log_gamma=0.1):\n",
    "        \"\"\"Performs a log transform log(gamma + x), and clips x values less than zero to zero.\"\"\"\n",
    "        return np.log(log_gamma + np.clip(data, 0, None))\n",
    "\n",
    "    def transform(self, data):\n",
    "        no_norm_scores = data[AS_IS_COLUMNS].astype(np.float64).values - 0.5\n",
    "        scores_to_norm = np.hstack([data[NORM_COLUMNS].astype(np.float64).values,\n",
    "                                    self._clip_and_log_transform(data[LOG_NORM_COLUMNS])])\n",
    "        normed = self.scaler.transform(scores_to_norm)\n",
    "        \n",
    "        MIMICzs = pd.DataFrame(np.hstack([no_norm_scores, normed]), columns=ALL_FEATURE_COLUMNS)\n",
    "        return self._preprocess_normalized_data(MIMICzs)\n",
    "    \n",
    "def extract_features_and_outcomes(df):\n",
    "    outcomes = df[C_DIED_IN_HOSP].values\n",
    "    covariates = df[ALL_FEATURE_COLUMNS]\n",
    "    return covariates, outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c9f48f83-d883-4c65-beff-1e099479b5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.34452994 0.08269689] [12.25048257  1.83913653]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = extract_features_and_outcomes(dataset[dataset[C_ICUSTAYID].isin(train_ids)])\n",
    "normer = DataNormalization(X_train)\n",
    "X_train = normer.transform(X_train).values\n",
    "\n",
    "X_val, y_val = extract_features_and_outcomes(dataset[dataset[C_ICUSTAYID].isin(val_ids)])\n",
    "X_val = normer.transform(X_val).values\n",
    "\n",
    "actions_train = np.hstack([\n",
    "    next_fluid_action[dataset[C_ICUSTAYID].isin(train_ids)].replace(pd.NA, np.nan).values.reshape(-1, 1),\n",
    "    next_vaso_action[dataset[C_ICUSTAYID].isin(train_ids)].replace(pd.NA, np.nan).values.reshape(-1, 1)\n",
    "]).astype(float)\n",
    "\n",
    "mean_action = actions_train[np.isnan(actions_train).sum(axis=1) == 0].mean(axis=0)\n",
    "std_action = actions_train[np.isnan(actions_train).sum(axis=1) == 0].std(axis=0)\n",
    "print(mean_action, std_action)\n",
    "norm_actions_train = (actions_train - mean_action) / std_action\n",
    "assert pd.isna(norm_actions_train[:,0]).sum() <= len(train_ids)\n",
    "norm_actions_train = np.where(np.isnan(norm_actions_train), 0, norm_actions_train) # Zero the nans since these are just at the end of each trajectory\n",
    "\n",
    "actions_val = np.hstack([\n",
    "    next_fluid_action[dataset[C_ICUSTAYID].isin(val_ids)].replace(pd.NA, np.nan).values.reshape(-1, 1),\n",
    "    next_vaso_action[dataset[C_ICUSTAYID].isin(val_ids)].replace(pd.NA, np.nan).values.reshape(-1, 1)\n",
    "])\n",
    "norm_actions_val = (actions_val - mean_action) / std_action\n",
    "assert pd.isna(norm_actions_val[:,0]).sum() <= len(val_ids)\n",
    "norm_actions_val = np.where(np.isnan(norm_actions_val), 0, norm_actions_val) # Zero the nans since these are just at the end of each trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e734ed6-7df7-4c90-bc3e-ee9f24c643a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nhead,\n",
    "                 nlayers, dropout = 0.5, rewards=True, values=True):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        # self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n",
    "        self.encoder_layers = []\n",
    "        self.norm_layers = []\n",
    "        for i in range(nlayers):\n",
    "            l = nn.MultiheadAttention(embed_dim, nhead, dropout=dropout)\n",
    "            norm = nn.LayerNorm(embed_dim)\n",
    "            self.encoder_layers.append(l)\n",
    "            self.norm_layers.append(norm)\n",
    "            self.add_module(f\"attention_{i}\", l)\n",
    "            self.add_module(f\"norm_{i}\", norm)\n",
    "        # Just don't use an encoder, pass the raw data directly into the transformer\n",
    "        # self.encoder = nn.Linear( # nn.Embedding(ntoken, d_model)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.decoder = nn.Linear(embed_dim, output_dim)\n",
    "        self.uncertainty_decoder = nn.Linear(embed_dim, output_dim)\n",
    "        self.predict_rewards = rewards\n",
    "        if rewards:\n",
    "            self.reward_decoder = nn.Linear(embed_dim, 2) # sigmoid for discharge, death\n",
    "        self.predict_values = values\n",
    "        if values:\n",
    "            self.value_decoder = nn.Linear(embed_dim, 1) # tanh for discounted rewards\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        # for l in self.encoder_layers:\n",
    "        #    l.weight.data.uniform_(-initrange, initrange)\n",
    "        self.embedding.bias.data.zero_()\n",
    "        torch.nn.init.xavier_normal_(self.embedding.weight.data)  # uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        torch.nn.init.xavier_normal_(self.decoder.weight.data) # uniform_(-initrange, initrange)\n",
    "        self.uncertainty_decoder.bias.data.fill_(1.0)\n",
    "        torch.nn.init.xavier_normal_(self.uncertainty_decoder.weight.data) # uniform_(-initrange, initrange)\n",
    "        if self.predict_rewards:\n",
    "            self.reward_decoder.bias.data.zero_()\n",
    "            torch.nn.init.xavier_normal_(self.reward_decoder.weight.data) #.uniform_(-initrange, initrange)\n",
    "        if self.predict_values:\n",
    "            self.value_decoder.bias.data.zero_()\n",
    "            torch.nn.init.xavier_normal_(self.value_decoder.weight.data) #.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        # seq_len = src.size(1)\n",
    "        src = self.embedding(src) # * np.sqrt(self.embed_dim) # self.encoder(src)\n",
    "        src = src.permute(1, 0, 2) # .reshape((-1, seq_len, src.size(2)))\n",
    "        # src = self.pos_encoder(src)\n",
    "        for l, norm in zip(self.encoder_layers, self.norm_layers):\n",
    "            transformed, _ = l(src, src, src, attn_mask=src_mask[:src.size(0),:src.size(0)])\n",
    "            src = norm(transformed + src)\n",
    "        # output = self.transformer_encoder(src, src_mask)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        output_mu = self.decoder(src)\n",
    "        output_sigma = F.softplus(self.uncertainty_decoder(src))\n",
    "        result = (torch.distributions.Normal(output_mu, output_sigma),)\n",
    "        if self.predict_rewards:\n",
    "            result = (*result, self.reward_decoder(src))\n",
    "        if self.predict_values:\n",
    "            result = (*result, torch.tanh(self.value_decoder(src)))\n",
    "        return result\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout = 0.1, max_len = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "6dc40791-d5de-4e6e-8974-d296fcda56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create next step prediction data\n",
    "class StateActionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, stay_ids, observations, actions, outcomes, replacement_values, sequence_length, gamma=0.95, mask_prob=0.0, next_step=True, forward_steps=[1], next_step_delta=False):\n",
    "        \"\"\"\n",
    "        stay_ids, observations, actions, and outcomes should all be the same length.\n",
    "        gamma = discount factor for value function.\n",
    "        mask_prob = probability of zeroing any value when returned.\n",
    "        next_step_delta = if True, return the feature-wise difference between the next step and the previous one.\n",
    "            if False, return the actual next step value\n",
    "        \"\"\"\n",
    "        assert len(stay_ids) == len(observations) == len(actions) == len(outcomes)\n",
    "        self.observations = observations\n",
    "        self.actions = actions\n",
    "        self.stay_ids = stay_ids\n",
    "        self.sequence_length = sequence_length\n",
    "        self.outcomes = outcomes\n",
    "        self.gamma = gamma\n",
    "        self.mask_prob = mask_prob\n",
    "        self.next_step = next_step\n",
    "        self.forward_steps = forward_steps\n",
    "        self.next_step_delta = next_step_delta\n",
    "        self.replacement_values = replacement_values\n",
    "        \n",
    "        self.stay_id_pos = []\n",
    "        last_stay_id = None\n",
    "        for i, stay_id in enumerate(self.stay_ids):\n",
    "            if last_stay_id != stay_id:\n",
    "                if self.stay_id_pos:\n",
    "                    self.stay_id_pos[-1] = (self.stay_id_pos[-1][0], i)\n",
    "                    if i - self.stay_id_pos[-1][0] <= max(forward_steps):\n",
    "                        del self.stay_id_pos[-1]\n",
    "                    assert i - 1 > self.stay_id_pos[-1][0], last_stay_id\n",
    "                self.stay_id_pos.append((i, 0))\n",
    "                last_stay_id = stay_id\n",
    "        self.stay_id_pos[-1] = (self.stay_id_pos[-1][0], len(self.stay_ids))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.stay_id_pos)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            observation sequence (N, L, O + A) - includes both observations and actions\n",
    "            next state (N, L, O)\n",
    "            next state missingness (N, L, O) - 1 if value was missing and imputed with median value, otherwise 0\n",
    "            rewards (N, 2) - one hot encoded\n",
    "            values (N) - discounted returns\n",
    "        \"\"\"\n",
    "        trajectory_indexes = np.arange(*self.stay_id_pos[index])\n",
    "        assert len(trajectory_indexes) > 0\n",
    "        observations = self.observations[trajectory_indexes]\n",
    "        actions = self.actions[trajectory_indexes]\n",
    "        outcomes = self.outcomes[trajectory_indexes]\n",
    "        \n",
    "        # Replace NaNs with median\n",
    "        obs_missing_mask = pd.isna(observations)\n",
    "        observations = np.where(obs_missing_mask, self.replacement_values, observations)\n",
    "        \n",
    "        input_obs = observations\n",
    "        if self.mask_prob > 0.0:\n",
    "            # Randomly replace observation values with the median\n",
    "            should_mask = np.logical_and(np.random.uniform(0.0, 1.0, size=input_obs.shape) < self.mask_prob,\n",
    "                                         1 - obs_missing_mask)\n",
    "            input_obs = np.where(should_mask, self.replacement_values, input_obs)\n",
    "        \n",
    "        if self.next_step:\n",
    "            num_to_truncate = max(self.forward_steps)\n",
    "            assert len(observations) > num_to_truncate\n",
    "            # Concatenate state and next action\n",
    "            input_vec = torch.from_numpy(np.hstack([input_obs, actions])[:-num_to_truncate]).float()\n",
    "            # Predict next state\n",
    "            next_state_vec = torch.from_numpy(np.hstack([observations[step:len(observations) - (num_to_truncate - step)] for step in self.forward_steps])).float()\n",
    "            if self.next_step_delta:\n",
    "                next_state_vec -= torch.cat([input_vec[:,:-2] for _ in range(len(self.forward_steps))], 1)\n",
    "            trajectory_indexes = trajectory_indexes[:-num_to_truncate]\n",
    "            outcomes = outcomes[:-num_to_truncate]\n",
    "            obs_missing_mask = torch.from_numpy(np.hstack([obs_missing_mask[step:len(obs_missing_mask) - (num_to_truncate - step)] for step in self.forward_steps]))\n",
    "        else:\n",
    "            input_vec = torch.from_numpy(np.hstack([input_obs, actions])).float()\n",
    "            # Predict the same state, without any masking\n",
    "            next_state_vec = torch.from_numpy(observations).float()\n",
    "            obs_missing_mask = torch.from_numpy(obs_missing_mask)\n",
    "        \n",
    "        rewards = np.zeros((len(trajectory_indexes), 2))\n",
    "        rewards[-1, outcomes[0]] = 1\n",
    "        rewards = torch.from_numpy(rewards).float()\n",
    "        discounted_rewards = torch.from_numpy(np.where(outcomes, -1, 1) * self.gamma ** np.flip(np.arange(1, len(trajectory_indexes) + 1))).unsqueeze(-1).float()\n",
    "        return input_vec, next_state_vec, obs_missing_mask, rewards, discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d461dd8c-742e-48a2-b06e-596d09a76da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65,) [-0.5        -0.5         1.70474809 -0.5         0.10689907  0.01587441\n",
      "  0.41353612 -0.19319987  0.57572019 -0.0750022  -0.14391165 -0.13726394\n",
      " -0.07501371 -0.08388254 -0.09768697 -0.1150351  -0.13072187 -0.07885488\n",
      " -0.07202734 -0.17116676 -0.02141068 -0.04139275 -0.08575785 -0.08010345\n",
      " -0.27156616 -0.15744149 -0.18493781 -0.10693429 -0.06147028 -0.00853773\n",
      " -0.24986746 -0.14843354 -0.05765314 -0.08171096 -0.11962336 -0.12306643\n",
      " -0.17836147 -0.17159384 -0.31574154 -0.28947092  0.125372   -0.20877026\n",
      " -0.18265836  0.07964647 -0.09804344 -0.07634549  0.12024069 -0.28743845\n",
      " -0.23693554 -0.4100593   0.1448369  -0.04034453 -0.23216959 -0.19165134\n",
      " -0.16701637 -0.23106465 -0.14774384 -0.29462532  0.27066171  0.3036274\n",
      "  0.22760832  0.35457279  0.09367429  0.03122987  0.5576041 ]\n"
     ]
    }
   ],
   "source": [
    "sequence_lengths_train = dataset[dataset[C_ICUSTAYID].isin(train_ids)].groupby(C_ICUSTAYID).agg({C_TIMESTEP: 'count'}).values\n",
    "max_seq_len = sequence_lengths_train.max()\n",
    "replacement_values = np.nanmedian(X_train, axis=0)\n",
    "print(replacement_values.shape, replacement_values)\n",
    "\n",
    "train_dataset = StateActionDataset(dataset[dataset[C_ICUSTAYID].isin(train_ids)][C_ICUSTAYID],\n",
    "                                   X_train,\n",
    "                                   norm_actions_train,\n",
    "                                   y_train,\n",
    "                                   replacement_values,\n",
    "                                   max_seq_len)\n",
    "val_dataset = StateActionDataset(dataset[dataset[C_ICUSTAYID].isin(val_ids)][C_ICUSTAYID],\n",
    "                                 X_val,\n",
    "                                 norm_actions_val,\n",
    "                                 y_val,\n",
    "                                 replacement_values,\n",
    "                                 max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa8a8e0c-43b3-460d-b08b-b157fb6f13d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gender', 0.5),\n",
       " ('mechvent', 0.5),\n",
       " ('max_dose_vaso', 5.941486177301741),\n",
       " ('re_admission', 0.5),\n",
       " ('age', 2.1490253666006334),\n",
       " ('elixhauser', 3.9137713898886),\n",
       " ('Height_cm', nan),\n",
       " ('Weight_kg', 8.931719091696516),\n",
       " ('GCS', nan),\n",
       " ('HR', 5.503894562618905),\n",
       " ('SysBP', nan),\n",
       " ('MeanBP', 7.934374419214472),\n",
       " ('DiaBP', nan),\n",
       " ('RR', 9.469691738624988),\n",
       " ('Temp_C', nan),\n",
       " ('FiO2_1', 3.5388773083270046),\n",
       " ('PAPsys', nan),\n",
       " ('PAPmean', nan),\n",
       " ('PAPdia', nan),\n",
       " ('CI', nan),\n",
       " ('Ionised_Ca', nan),\n",
       " ('CO2_mEqL', nan),\n",
       " ('Total_protein', nan),\n",
       " ('Albumin', nan),\n",
       " ('Troponin', nan),\n",
       " ('CRP', nan),\n",
       " ('ACT', nan),\n",
       " ('Potassium', nan),\n",
       " ('Sodium', nan),\n",
       " ('Chloride', nan),\n",
       " ('Glucose', nan),\n",
       " ('Magnesium', nan),\n",
       " ('Calcium', nan),\n",
       " ('Hb', nan),\n",
       " ('Ht', nan),\n",
       " ('RBC_count', nan),\n",
       " ('WBC_count', nan),\n",
       " ('Platelets_count', nan),\n",
       " ('PTT', nan),\n",
       " ('PT', nan),\n",
       " ('Arterial_pH', nan),\n",
       " ('paO2', nan),\n",
       " ('paCO2', nan),\n",
       " ('Arterial_BE', nan),\n",
       " ('HCO3', nan),\n",
       " ('ETCO2', nan),\n",
       " ('SvO2', nan),\n",
       " ('Arterial_lactate', nan),\n",
       " ('SOFA', 5.297110495722087),\n",
       " ('SIRS', 2.5743497707830745),\n",
       " ('SpO2', nan),\n",
       " ('BUN', nan),\n",
       " ('Creatinine', nan),\n",
       " ('SGOT', nan),\n",
       " ('SGPT', nan),\n",
       " ('Total_bili', nan),\n",
       " ('Direct_bili', nan),\n",
       " ('INR', nan),\n",
       " ('input_total', 1.6877031656086634),\n",
       " ('input_step', 1.7287938159548846),\n",
       " ('output_total', 2.2655832798490283),\n",
       " ('output_step', 1.6959231320358257),\n",
       " ('Shock_Index', 13.832337237729543),\n",
       " ('PaO2_FiO2', nan),\n",
       " ('cumulated_balance', 1.469141215537283)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(ALL_FEATURE_COLUMNS, X_train.max(axis=0).astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e9ad1d4c-f79e-4c20-8f3d-02d1a4ca01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_size = X_train.shape[1]  # embedding dimension\n",
    "embed_size = 128\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.5  # dropout probability\n",
    "model = TransformerModel(obs_size + 2, embed_size, obs_size, nhead, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f4a34-6154-45a2-947e-1c5722bb2504",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DON't RUN - Just create a padded sequence dataset\n",
    "X_train_padded = torch.zeros((len(train_ids), max_seq_len, X_train.shape[1]))\n",
    "\n",
    "curr_seq_row = 0\n",
    "curr_seq_pos = 0\n",
    "curr_stay_id = None\n",
    "train_stay_ids = dataset[dataset[C_ICUSTAYID].isin(train_ids)][C_ICUSTAYID]\n",
    "for i in tqdm.tqdm(range(len(X_train))):\n",
    "    if curr_stay_id is None: curr_stay_id = train_stay_ids[i]\n",
    "    if train_stay_ids[i] != curr_stay_id:\n",
    "        curr_seq_row += 1\n",
    "        curr_seq_pos = 0\n",
    "    X_train_padded[curr_seq_row, curr_seq_pos, :] = torch.from_numpy(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48cae54c-f397-4b05-b685-1d8625cfa735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader with sequence padding\n",
    "def pad_collate(batch):\n",
    "    arrays_to_pad = list(zip(*batch))\n",
    "    x_lens = [len(x) for x in arrays_to_pad[0]]\n",
    "    # y_lens = [len(y) for y in yy]\n",
    "\n",
    "    padded_arrays = [pad_sequence(xx, batch_first=True, padding_value=0) for xx in arrays_to_pad]\n",
    "\n",
    "    return (*padded_arrays, torch.LongTensor(x_lens))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a6cc28fc-0ea8-4b5c-bcba-81f48b6fb7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.5000, -0.5000,  1.7405, -0.5000,  0.4782,  0.8821,  0.4135, -0.1932,\n",
       "          0.5757, -0.2161, -0.1439, -1.4447, -0.0750,  0.2206,  1.4254, -0.1150,\n",
       "         -0.1307, -0.0789, -0.0720, -0.1712, -0.0214, -0.0414, -0.0858, -0.0801,\n",
       "         -0.2716, -0.1574, -0.1849, -0.1069, -0.0615, -0.0085, -0.2499, -0.1484,\n",
       "         -0.0577, -0.0817, -0.1196, -0.1231, -0.1784, -0.1716, -0.3157, -0.2895,\n",
       "          0.1254, -0.2088, -0.1827,  0.0796, -0.0980, -0.0763,  0.1202, -0.2874,\n",
       "         -0.2369, -0.4101, -0.3353, -0.0403, -0.2322, -0.1917, -0.1670, -0.2311,\n",
       "         -0.1477, -0.2946,  0.2707,  1.0802,  0.2276,  0.3546,  0.6668,  0.0312,\n",
       "          0.5466,  0.9838,  0.0638]),\n",
       " tensor([-0.5000, -0.5000,  1.7405, -0.5000,  0.4782,  0.8821,  0.4135,  1.0513,\n",
       "          0.5757, -0.2161, -1.1049, -1.4447, -1.1480,  0.2206,  1.4254, -0.7044,\n",
       "         -0.1307, -0.0789, -0.0720, -0.1712, -0.0214, -0.0414, -0.0858, -0.0801,\n",
       "         -0.2716, -0.1574, -0.1849, -0.1069, -0.0615, -0.0085, -0.2499, -0.1484,\n",
       "         -0.0577, -0.0817, -0.1196, -0.1231, -0.1784, -0.1716, -0.3157, -0.2895,\n",
       "          0.1254, -0.2088, -0.1827,  0.0796, -0.0980, -0.0763,  0.1202, -0.2874,\n",
       "          0.4548, -0.4101, -0.3353, -0.0403, -0.2322, -0.1917, -0.1670, -0.2311,\n",
       "         -0.1477, -0.2946, -0.1803,  1.0802, -3.6784, -2.2955,  0.6668,  0.0312,\n",
       "          0.5466]),\n",
       " array([False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False,\n",
       "         True, False]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_item = train_dataset[102]\n",
    "test_item[0][0], test_item[1][0], test_item[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92a603-6791-4169-ac12-010ea68ed523",
   "metadata": {},
   "source": [
    "# Imputation\n",
    "\n",
    "Let's first train a model to predict masked values in the input, to improve some of the missingness in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "208b1eb9-5d16-4877-a79b-2a6d4bf5aa1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: -24.013664: 100%|█████████| 518/518 [00:09<00:00, 55.85it/s]\n",
      "Val loss: -29.469269: 100%|█████████████████████| 58/58 [00:00<00:00, 88.52it/s]\n",
      "Epoch 2 train loss: -31.481637: 100%|█████████| 518/518 [00:09<00:00, 56.05it/s]\n",
      "Val loss: -33.671433: 100%|█████████████████████| 58/58 [00:00<00:00, 86.06it/s]\n",
      "Epoch 3 train loss: -34.542107: 100%|█████████| 518/518 [00:09<00:00, 56.33it/s]\n",
      "Val loss: -35.858437: 100%|█████████████████████| 58/58 [00:00<00:00, 89.63it/s]\n",
      "Epoch 4 train loss: -36.067143: 100%|█████████| 518/518 [00:09<00:00, 56.80it/s]\n",
      "Val loss: -37.271532: 100%|█████████████████████| 58/58 [00:00<00:00, 88.81it/s]\n",
      "Epoch 5 train loss: -36.971666: 100%|█████████| 518/518 [00:09<00:00, 56.66it/s]\n",
      "Val loss: -37.668977: 100%|█████████████████████| 58/58 [00:00<00:00, 85.28it/s]\n",
      "Epoch 6 train loss: -37.571922: 100%|█████████| 518/518 [00:09<00:00, 55.05it/s]\n",
      "Val loss: -38.574482: 100%|█████████████████████| 58/58 [00:00<00:00, 88.44it/s]\n",
      "Epoch 7 train loss: -38.059200: 100%|█████████| 518/518 [00:09<00:00, 54.46it/s]\n",
      "Val loss: -38.599956: 100%|█████████████████████| 58/58 [00:00<00:00, 82.96it/s]\n",
      "Epoch 8 train loss: -38.456438: 100%|█████████| 518/518 [00:09<00:00, 54.68it/s]\n",
      "Val loss: -37.661449: 100%|█████████████████████| 58/58 [00:00<00:00, 84.48it/s]\n",
      "Epoch 9 train loss: -38.747733: 100%|█████████| 518/518 [00:09<00:00, 53.99it/s]\n",
      "Val loss: -38.990753: 100%|█████████████████████| 58/58 [00:00<00:00, 86.99it/s]\n",
      "Epoch 10 train loss: -39.005233: 100%|████████| 518/518 [00:09<00:00, 53.98it/s]\n",
      "Val loss: -39.522593: 100%|█████████████████████| 58/58 [00:00<00:00, 84.13it/s]\n",
      "Epoch 11 train loss: -39.209236: 100%|████████| 518/518 [00:09<00:00, 53.38it/s]\n",
      "Val loss: -39.742487: 100%|█████████████████████| 58/58 [00:00<00:00, 85.07it/s]\n",
      "Epoch 12 train loss: -39.445410: 100%|████████| 518/518 [00:09<00:00, 55.77it/s]\n",
      "Val loss: -40.291302: 100%|█████████████████████| 58/58 [00:00<00:00, 88.38it/s]\n",
      "Epoch 13 train loss: -39.624140: 100%|████████| 518/518 [00:09<00:00, 55.36it/s]\n",
      "Val loss: -40.324686: 100%|█████████████████████| 58/58 [00:00<00:00, 89.30it/s]\n",
      "Epoch 14 train loss: -39.769315: 100%|████████| 518/518 [00:09<00:00, 55.79it/s]\n",
      "Val loss: -39.867850: 100%|█████████████████████| 58/58 [00:00<00:00, 89.28it/s]\n",
      "Epoch 15 train loss: -39.913762: 100%|████████| 518/518 [00:09<00:00, 55.90it/s]\n",
      "Val loss: -40.399265: 100%|█████████████████████| 58/58 [00:00<00:00, 89.11it/s]\n",
      "Epoch 16 train loss: -40.060884: 100%|████████| 518/518 [00:09<00:00, 55.80it/s]\n",
      "Val loss: -40.328405: 100%|█████████████████████| 58/58 [00:00<00:00, 89.52it/s]\n",
      "Epoch 17 train loss: -40.151740: 100%|████████| 518/518 [00:09<00:00, 54.20it/s]\n",
      "Val loss: -40.541288: 100%|█████████████████████| 58/58 [00:00<00:00, 89.13it/s]\n",
      "Epoch 18 train loss: -40.282156: 100%|████████| 518/518 [00:09<00:00, 55.47it/s]\n",
      "Val loss: -40.522754: 100%|█████████████████████| 58/58 [00:00<00:00, 89.65it/s]\n",
      "Epoch 19 train loss: -40.369178: 100%|████████| 518/518 [00:09<00:00, 55.37it/s]\n",
      "Val loss: -40.779532: 100%|█████████████████████| 58/58 [00:00<00:00, 86.34it/s]\n",
      "Epoch 20 train loss: -40.519575: 100%|████████| 518/518 [00:09<00:00, 55.16it/s]\n",
      "Val loss: -40.720960: 100%|█████████████████████| 58/58 [00:00<00:00, 85.35it/s]\n",
      "Epoch 21 train loss: -40.582999: 100%|████████| 518/518 [00:09<00:00, 55.33it/s]\n",
      "Val loss: -41.008016: 100%|█████████████████████| 58/58 [00:00<00:00, 89.36it/s]\n",
      "Epoch 22 train loss: -40.686186: 100%|████████| 518/518 [00:09<00:00, 55.77it/s]\n",
      "Val loss: -40.639089: 100%|█████████████████████| 58/58 [00:00<00:00, 91.07it/s]\n",
      "Epoch 23 train loss: -40.762601: 100%|████████| 518/518 [00:09<00:00, 54.02it/s]\n",
      "Val loss: -40.884831: 100%|█████████████████████| 58/58 [00:00<00:00, 85.05it/s]\n",
      "Epoch 24 train loss: -40.811802: 100%|████████| 518/518 [00:09<00:00, 55.43it/s]\n",
      "Val loss: -41.157399: 100%|█████████████████████| 58/58 [00:00<00:00, 89.72it/s]\n",
      "Epoch 25 train loss: -40.882305: 100%|████████| 518/518 [00:09<00:00, 55.12it/s]\n",
      "Val loss: -41.017079: 100%|█████████████████████| 58/58 [00:00<00:00, 87.38it/s]\n",
      "Epoch 26 train loss: -40.948833: 100%|████████| 518/518 [00:09<00:00, 53.85it/s]\n",
      "Val loss: -40.982742: 100%|█████████████████████| 58/58 [00:00<00:00, 88.10it/s]\n",
      "Epoch 27 train loss: -41.008047: 100%|████████| 518/518 [00:09<00:00, 54.57it/s]\n",
      "Val loss: -41.487724: 100%|█████████████████████| 58/58 [00:00<00:00, 81.27it/s]\n",
      "Epoch 28 train loss: -41.085081: 100%|████████| 518/518 [00:09<00:00, 54.08it/s]\n",
      "Val loss: -41.573548: 100%|█████████████████████| 58/58 [00:00<00:00, 82.50it/s]\n",
      "Epoch 29 train loss: -41.162238: 100%|████████| 518/518 [00:09<00:00, 52.20it/s]\n",
      "Val loss: -41.360508: 100%|█████████████████████| 58/58 [00:00<00:00, 83.45it/s]\n",
      "Epoch 30 train loss: -41.218428: 100%|████████| 518/518 [00:09<00:00, 52.54it/s]\n",
      "Val loss: -41.730953: 100%|█████████████████████| 58/58 [00:00<00:00, 81.66it/s]\n",
      "Epoch 31 train loss: -41.247514: 100%|████████| 518/518 [00:09<00:00, 51.84it/s]\n",
      "Val loss: -41.493122: 100%|█████████████████████| 58/58 [00:00<00:00, 84.40it/s]\n",
      "Epoch 32 train loss: -41.268236: 100%|████████| 518/518 [00:09<00:00, 52.42it/s]\n",
      "Val loss: -41.577525: 100%|█████████████████████| 58/58 [00:00<00:00, 84.61it/s]\n",
      "Epoch 33 train loss: -41.309770: 100%|████████| 518/518 [00:09<00:00, 52.88it/s]\n",
      "Val loss: -41.750664: 100%|█████████████████████| 58/58 [00:00<00:00, 84.04it/s]\n",
      "Epoch 34 train loss: -41.427516: 100%|████████| 518/518 [00:09<00:00, 52.56it/s]\n",
      "Val loss: -41.585731: 100%|█████████████████████| 58/58 [00:00<00:00, 83.19it/s]\n",
      "Epoch 35 train loss: -41.402276: 100%|████████| 518/518 [00:09<00:00, 53.16it/s]\n",
      "Val loss: -41.413255: 100%|█████████████████████| 58/58 [00:00<00:00, 85.79it/s]\n",
      "Epoch 36 train loss: -41.468057: 100%|████████| 518/518 [00:09<00:00, 52.93it/s]\n",
      "Val loss: -42.000176: 100%|█████████████████████| 58/58 [00:00<00:00, 84.29it/s]\n",
      "Epoch 37 train loss: -41.498452: 100%|████████| 518/518 [00:09<00:00, 52.31it/s]\n",
      "Val loss: -41.598138: 100%|█████████████████████| 58/58 [00:00<00:00, 82.34it/s]\n",
      "Epoch 38 train loss: -41.508070: 100%|████████| 518/518 [00:09<00:00, 51.88it/s]\n",
      "Val loss: -41.926113: 100%|█████████████████████| 58/58 [00:00<00:00, 81.85it/s]\n",
      "Epoch 39 train loss: -41.542413: 100%|████████| 518/518 [00:10<00:00, 51.54it/s]\n",
      "Val loss: -41.811077: 100%|█████████████████████| 58/58 [00:00<00:00, 85.96it/s]\n",
      "Epoch 40 train loss: -41.673446: 100%|████████| 518/518 [00:09<00:00, 52.17it/s]\n",
      "Val loss: -42.088133: 100%|█████████████████████| 58/58 [00:00<00:00, 82.13it/s]\n",
      "Epoch 41 train loss: -41.643442: 100%|████████| 518/518 [00:09<00:00, 53.04it/s]\n",
      "Val loss: -41.931481: 100%|█████████████████████| 58/58 [00:00<00:00, 84.40it/s]\n",
      "Epoch 42 train loss: -41.703466: 100%|████████| 518/518 [00:09<00:00, 52.91it/s]\n",
      "Val loss: -42.153633: 100%|█████████████████████| 58/58 [00:00<00:00, 83.33it/s]\n",
      "Epoch 43 train loss: -41.715027: 100%|████████| 518/518 [00:09<00:00, 52.95it/s]\n",
      "Val loss: -42.308021: 100%|█████████████████████| 58/58 [00:00<00:00, 83.24it/s]\n",
      "Epoch 44 train loss: -41.747490: 100%|████████| 518/518 [00:09<00:00, 51.82it/s]\n",
      "Val loss: -42.244550: 100%|█████████████████████| 58/58 [00:00<00:00, 82.25it/s]\n",
      "Epoch 45 train loss: -41.755316: 100%|████████| 518/518 [00:10<00:00, 51.40it/s]\n",
      "Val loss: -42.154953: 100%|█████████████████████| 58/58 [00:00<00:00, 82.68it/s]\n",
      "Epoch 46 train loss: -41.801635: 100%|████████| 518/518 [00:10<00:00, 51.46it/s]\n",
      "Val loss: -41.965578: 100%|█████████████████████| 58/58 [00:00<00:00, 83.95it/s]\n",
      "Epoch 47 train loss: -41.765091: 100%|████████| 518/518 [00:09<00:00, 53.08it/s]\n",
      "Val loss: -42.122263: 100%|█████████████████████| 58/58 [00:00<00:00, 84.61it/s]\n",
      "Epoch 48 train loss: -41.836607: 100%|████████| 518/518 [00:09<00:00, 52.98it/s]\n",
      "Val loss: -42.184196: 100%|█████████████████████| 58/58 [00:00<00:00, 82.76it/s]\n",
      "Epoch 49 train loss: -41.902889: 100%|████████| 518/518 [00:10<00:00, 51.54it/s]\n",
      "Val loss: -42.142709: 100%|█████████████████████| 58/58 [00:00<00:00, 82.15it/s]\n",
      "Epoch 50 train loss: -41.946645: 100%|████████| 518/518 [00:10<00:00, 51.60it/s]\n",
      "Val loss: -42.189524: 100%|█████████████████████| 58/58 [00:00<00:00, 81.33it/s]\n",
      "Epoch 51 train loss: -41.938904: 100%|████████| 518/518 [00:10<00:00, 51.11it/s]\n",
      "Val loss: -42.724140: 100%|█████████████████████| 58/58 [00:00<00:00, 79.34it/s]\n",
      "Epoch 52 train loss: -41.920773: 100%|████████| 518/518 [00:10<00:00, 51.77it/s]\n",
      "Val loss: -42.482313: 100%|█████████████████████| 58/58 [00:00<00:00, 83.63it/s]\n",
      "Epoch 53 train loss: -41.982260: 100%|████████| 518/518 [00:09<00:00, 53.38it/s]\n",
      "Val loss: -42.393570: 100%|█████████████████████| 58/58 [00:00<00:00, 84.11it/s]\n",
      "Epoch 54 train loss: -42.020097: 100%|████████| 518/518 [00:09<00:00, 52.27it/s]\n",
      "Val loss: -42.254430: 100%|█████████████████████| 58/58 [00:00<00:00, 81.33it/s]\n",
      "Epoch 55 train loss: -42.023690: 100%|████████| 518/518 [00:10<00:00, 50.33it/s]\n",
      "Val loss: -42.067118: 100%|█████████████████████| 58/58 [00:00<00:00, 74.14it/s]\n",
      "Epoch 56 train loss: -42.105873: 100%|████████| 518/518 [00:10<00:00, 49.59it/s]\n",
      "Val loss: -42.498221: 100%|█████████████████████| 58/58 [00:00<00:00, 82.47it/s]\n",
      "Epoch 57 train loss: -42.087145: 100%|████████| 518/518 [00:10<00:00, 49.46it/s]\n",
      "Val loss: -42.513356: 100%|█████████████████████| 58/58 [00:00<00:00, 80.23it/s]\n",
      "Epoch 58 train loss: -42.112258: 100%|████████| 518/518 [00:10<00:00, 51.57it/s]\n",
      "Val loss: -42.365962: 100%|█████████████████████| 58/58 [00:00<00:00, 82.59it/s]\n",
      "Epoch 59 train loss: -42.174714: 100%|████████| 518/518 [00:10<00:00, 51.57it/s]\n",
      "Val loss: -42.272751: 100%|█████████████████████| 58/58 [00:00<00:00, 82.89it/s]\n",
      "Epoch 60 train loss: -42.190387: 100%|████████| 518/518 [00:09<00:00, 52.04it/s]\n",
      "Val loss: -42.852477: 100%|█████████████████████| 58/58 [00:00<00:00, 83.18it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_prob = 0.5\n",
    "\n",
    "train_dataset = StateActionDataset(dataset[dataset[C_ICUSTAYID].isin(train_ids)][C_ICUSTAYID],\n",
    "                                   X_train,\n",
    "                                   norm_actions_train,\n",
    "                                   y_train,\n",
    "                                   replacement_values,\n",
    "                                   max_seq_len,\n",
    "                                   next_step=False,\n",
    "                                  mask_prob=mask_prob)\n",
    "val_dataset = StateActionDataset(dataset[dataset[C_ICUSTAYID].isin(val_ids)][C_ICUSTAYID],\n",
    "                                 X_val,\n",
    "                                 norm_actions_val,\n",
    "                                 y_val,\n",
    "                                 replacement_values,\n",
    "                                 max_seq_len,\n",
    "                                 next_step=False,\n",
    "                                mask_prob=mask_prob)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "regularization_factor = 20.0\n",
    "def reconstruction_loss_aleatoric(pred, true):\n",
    "    neg_log_likelihood = -pred.log_prob(true)\n",
    "    return neg_log_likelihood + regularization_factor * torch.log(pred.scale)\n",
    "\n",
    "reconstruction_criterion = reconstruction_loss_aleatoric # nn.MSELoss(reduction='none')\n",
    "\n",
    "obs_size = X_train.shape[1]  # embedding dimension\n",
    "embed_size = 128\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.5  # dropout probability\n",
    "model = TransformerModel(obs_size + 2, embed_size, obs_size, nhead, nlayers, dropout, rewards=False, values=False).to(device)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "lr = 1e-2  # learning rate\n",
    "reward_lambda = 10.0\n",
    "value_lambda = 10.0\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "seq_len = 160\n",
    "grad_norm_clip = 10.0\n",
    "\n",
    "early_stop_threshold = 10\n",
    "num_nonincreasing = 0\n",
    "minimum_val_loss = 1e9\n",
    "\n",
    "# results.setdefault(model_name, {})\n",
    "for epoch in range(60):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader), ncols=80)\n",
    "    for i, (inputs, outputs, missingness_mask, rewards, discounted_rewards, in_lens) in bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        (pred,) = model(inputs, torch.ones(seq_len, seq_len))\n",
    "        loss_mask = torch.logical_and(torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None],\n",
    "                                      ~missingness_mask)\n",
    "\n",
    "        l1 = reconstruction_criterion(pred, outputs)\n",
    "        loss_masked = l1.where(loss_mask, torch.tensor(0.0))\n",
    "        loss = loss_masked.sum() / loss_mask.sum()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        bar.set_description(f\"Epoch {epoch + 1} train loss: {total_loss / (i + 1):.6f}\")\n",
    "    # results[model_name].setdefault(\"train_loss\", []).append(total_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        bar = tqdm.tqdm(enumerate(val_loader), total=len(val_loader), ncols=80)\n",
    "        for i, (inputs, outputs, missingness_mask, rewards, discounted_rewards, in_lens) in bar:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            \n",
    "            (pred,) = model(inputs, torch.ones(seq_len, seq_len))\n",
    "            loss_mask = torch.logical_and(torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None],\n",
    "                                          ~missingness_mask)\n",
    "\n",
    "            l1 = reconstruction_criterion(pred, outputs)\n",
    "            loss_masked = l1.where(loss_mask, torch.tensor(0.0))\n",
    "            loss = loss_masked.sum() / loss_mask.sum()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            bar.set_description(f\"Val loss: {total_loss / (i + 1):.6f}\")\n",
    "    # results[model_name].setdefault(\"val_loss\", []).append(total_loss / len(val_loader))\n",
    "    if total_loss < minimum_val_loss:\n",
    "        minimum_val_loss = total_loss\n",
    "        num_nonincreasing = 0\n",
    "    else:\n",
    "        num_nonincreasing += 1\n",
    "        if num_nonincreasing == early_stop_threshold:\n",
    "            print(\"Early stop.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), f\"data/transformer_embedding_model/imputation_model_{mask_prob}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7ee63107-6857-4641-830c-1ebfda1f0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_states(stay_ids, observations, actions):\n",
    "    eval_dataset = StateActionDataset(stay_ids,\n",
    "                                      observations,\n",
    "                                      actions,\n",
    "                                      np.zeros(len(actions), dtype=int),\n",
    "                                      replacement_values,\n",
    "                                      max_seq_len,\n",
    "                                      next_step=False)\n",
    "    print(len(stay_ids))\n",
    "    batch_size = 32\n",
    "    eval_loader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)\n",
    "    \n",
    "    model.eval()\n",
    "    predicted_states = []\n",
    "    predicted_state_stds = []\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm.tqdm(enumerate(eval_loader), total=len(eval_loader), ncols=80)\n",
    "        for i, (inputs, outputs, missingness_mask, rewards, discounted_rewards, in_lens) in bar:\n",
    "            inputs = inputs.to(device)            \n",
    "\n",
    "            (pred,) = model(inputs, torch.ones(seq_len, seq_len))\n",
    "            predicted_states += [x[:l] for x, l in zip(pred.loc.cpu().numpy(), in_lens.numpy())]\n",
    "            predicted_state_stds += [x[:l] for x, l in zip(pred.scale.cpu().numpy(), in_lens.numpy())]\n",
    "            \n",
    "    return np.concatenate(predicted_states), np.concatenate(predicted_state_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "78a314ae-17a7-4935-ba18-00761044451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 116.28it/s]\n"
     ]
    }
   ],
   "source": [
    "val_stay_ids = dataset[dataset[C_ICUSTAYID].isin(val_ids)][C_ICUSTAYID]\n",
    "pred_state, pred_state_std = impute_states(val_stay_ids,\n",
    "                                           X_val,\n",
    "                                           norm_actions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "7fe992e9-beca-4dea-8af7-57c8727c44d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_of_interest = C_PT\n",
    "\n",
    "val_example = np.random.choice(val_stay_ids[np.isnan(X_val[:,ALL_FEATURE_COLUMNS.index(feature_of_interest)]) == 0])\n",
    "example_indexes = val_stay_ids == val_example\n",
    "\n",
    "true_states = X_val[example_indexes]\n",
    "pred_states = pred_state[example_indexes]\n",
    "pred_state_stds = pred_state_std[example_indexes]\n",
    "\n",
    "plt.figure(figsize=(5, 2), dpi=180)\n",
    "plt.plot(true_states[:, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "# plt.plot(true_states[:-1, ALL_FEATURE_COLUMNS.index(feature_of_interest)] + pred_states[:-1, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "plt.plot(pred_states[:, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "plt.fill_between(np.arange(len(pred_states)), \n",
    "                pred_states[:, ALL_FEATURE_COLUMNS.index(feature_of_interest)] - 1.96 * pred_state_stds[:, ALL_FEATURE_COLUMNS.index(feature_of_interest)],\n",
    "                pred_states[:, ALL_FEATURE_COLUMNS.index(feature_of_interest)] + 1.96 * pred_state_stds[:, ALL_FEATURE_COLUMNS.index(feature_of_interest)],\n",
    "                alpha=0.2)\n",
    "plt.title(feature_of_interest)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc3f9b-029f-440a-af68-1d789c42bf16",
   "metadata": {},
   "source": [
    "# Next-Step Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "7a23507b-5343-4409-b86d-0c2675cbf0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_size = X_train.shape[1]  # embedding dimension\n",
    "embed_size = 128\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.5  # dropout probability\n",
    "model = TransformerModel(obs_size + 2, embed_size, obs_size, nhead, nlayers, dropout, rewards=False, values=False).to(device)\n",
    "mask_prob = 0.5\n",
    "\n",
    "state_dict = torch.load(f\"data/transformer_embedding_model/imputation_model_{mask_prob}.pt\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "88735d37-4943-44e0-8173-e5d68825cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 518/518 [00:03<00:00, 142.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 4145537\n",
      "After: 0\n",
      "20865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 147.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 458783\n",
      "After: 0\n"
     ]
    }
   ],
   "source": [
    "# Use the previous model to impute states for the missing data\n",
    "train_stay_ids = dataset[dataset[C_ICUSTAYID].isin(train_ids)][C_ICUSTAYID]\n",
    "pred_state, pred_state_std = impute_states(train_stay_ids,\n",
    "                                           X_train,\n",
    "                                           norm_actions_train)\n",
    "print(\"Before:\", np.isnan(X_train).sum())\n",
    "X_train_imputed = np.where(np.isnan(X_train), pred_state, X_train)\n",
    "print(\"After:\", np.isnan(X_train_imputed).sum())\n",
    "\n",
    "val_stay_ids = dataset[dataset[C_ICUSTAYID].isin(val_ids)][C_ICUSTAYID]\n",
    "pred_state, pred_state_std = impute_states(val_stay_ids,\n",
    "                                           X_val,\n",
    "                                           norm_actions_val)\n",
    "print(\"Before:\", np.isnan(X_val).sum())\n",
    "X_val_imputed = np.where(np.isnan(X_val), pred_state, X_val)\n",
    "print(\"After:\", np.isnan(X_val_imputed).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "f1913e7c-3d26-41e2-ae3d-1751a37e976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NextStateRNN(X_train.shape[1], 2, bidirectional=True)\n",
    "regularization_factor = 20.0\n",
    "def reconstruction_loss_aleatoric(pred, true):\n",
    "    neg_log_likelihood = -pred.log_prob(true)\n",
    "    return neg_log_likelihood + regularization_factor * torch.log(1.0 + pred.scale)\n",
    "\n",
    "def reconstruction_sign(pred, true):\n",
    "    \"\"\"Penalize the model for having low probability of a delta with the correct sign.\"\"\"\n",
    "    left_area = pred.cdf(0.0)\n",
    "    return -((true > 0).float() * torch.clamp(torch.log(1 - left_area), min=-100) + (true < 0).float() * torch.clamp(torch.log(left_area), min=-100))\n",
    "\n",
    "reconstruction_criterion = reconstruction_loss_aleatoric # nn.MSELoss(reduction='none')\n",
    "reconstruction_sign_criterion = nn.BCELoss(reduction='none')\n",
    "reward_criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "value_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "18a6f60f-aa13-455b-929c-32717a86197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset (constant across bootstrapped replicates)\n",
    "\n",
    "val_dataset = StateActionDataset(dataset[dataset[C_ICUSTAYID].isin(val_ids)][C_ICUSTAYID],\n",
    "                                 X_val_imputed,\n",
    "                                 norm_actions_val,\n",
    "                                 y_val,\n",
    "                                 replacement_values,\n",
    "                                 max_seq_len,\n",
    "                                 next_step=True,\n",
    "                                 forward_steps=[1, 2, 4],\n",
    "                                 next_step_delta=True)\n",
    "batch_size = 32\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3321c-9207-4491-a24a-f47abe716ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training a single model\n",
    "\n",
    "obs_size = X_train.shape[1]  # embedding dimension\n",
    "embed_size = 256\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 8  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.5  # dropout probability\n",
    "model = TransformerModel(obs_size + 2, embed_size, obs_size * 3, nhead, nlayers, dropout).to(device)\n",
    "\n",
    "train_dataset = StateActionDataset(dataset[dataset[C_ICUSTAYID].isin(train_ids)][C_ICUSTAYID],\n",
    "                                 X_train_imputed,\n",
    "                                 norm_actions_train,\n",
    "                                 y_train,\n",
    "                                 replacement_values,\n",
    "                                 max_seq_len,\n",
    "                                 next_step=True,\n",
    "                                 forward_steps=[1, 2, 4],\n",
    "                                 next_step_delta=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "lr = 1e-2  # learning rate\n",
    "reward_lambda = 10.0\n",
    "value_lambda = 10.0\n",
    "sign_lambda = 10.0\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "seq_len = 160\n",
    "output_scaling_factor = 1.0\n",
    "grad_norm_clip = 5.0\n",
    "\n",
    "# results.setdefault(model_name, {})\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader), ncols=80)\n",
    "    for i, (inputs, outputs, _, rewards, discounted_rewards, in_lens) in bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        rewards = rewards.to(device)\n",
    "        discounted_rewards = discounted_rewards.to(device)\n",
    "\n",
    "        pred, pred_rewards, pred_value = model(inputs, src_mask)\n",
    "        # print(pred.shape, outputs.shape, pred_rewards.shape, rewards.shape)\n",
    "        # print(pred.shape, outputs.shape, pred_rewards.shape, rewards.shape, pred_value.shape, discounted_rewards.shape)\n",
    "        loss_mask = torch.arange(inputs.shape[1])[None, :] < in_lens[:, None]\n",
    "\n",
    "        # Idea: weight the examples by how big the change is in each feature\n",
    "        timestep_weights = (outputs ** 2)\n",
    "\n",
    "        l1 = ((reconstruction_criterion(pred, outputs * output_scaling_factor) + sign_lambda * reconstruction_sign_criterion(pred.cdf(0.0), (outputs < 0).float())) * timestep_weights).sum(2)\n",
    "        l2 = reward_criterion(pred_rewards, rewards).sum(2)\n",
    "        l3 = value_criterion(pred_value, discounted_rewards).sum(2)\n",
    "        # print(reconstruction_sign_criterion(pred, outputs * output_scaling_factor))\n",
    "        loss_masked = (l1 + \n",
    "                       reward_lambda * l2 + \n",
    "                       value_lambda * l3\n",
    "                      ).where(loss_mask, torch.tensor(0.0))\n",
    "        loss = loss_masked.sum() / loss_mask.sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        bar.set_description(f\"Train loss: {total_loss / (i + 1):.6f}\")\n",
    "    # results[model_name].setdefault(\"train_loss\", []).append(total_loss / len(train_loader))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_losses = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        bar = tqdm.tqdm(enumerate(val_loader), total=len(val_loader), ncols=80)\n",
    "        for i, (inputs, outputs, _, rewards, discounted_rewards, in_lens) in bar:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            rewards = rewards.to(device)\n",
    "            discounted_rewards = discounted_rewards.to(device)\n",
    "            \n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "            pred, pred_rewards, pred_value = model(inputs, src_mask)\n",
    "            loss_mask = torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None]\n",
    "\n",
    "            timestep_weights = (outputs ** 2)# .mean(2)\n",
    "            # timestep_weights /= timestep_weights.sum(1, keepdim=True)\n",
    "\n",
    "            reconstruction_loss = ((reconstruction_criterion(pred, outputs * output_scaling_factor) + sign_lambda * reconstruction_sign_criterion(pred.cdf(0.0), (outputs < 0).float())) * timestep_weights).sum(2).where(loss_mask.squeeze(2), torch.tensor(0.0)).sum()\n",
    "            reward_loss = reward_criterion(pred_rewards, rewards).where(loss_mask, torch.tensor(0.0)).sum()\n",
    "            value_loss = value_criterion(pred_value, discounted_rewards).where(loss_mask, torch.tensor(0.0)).sum()\n",
    "            sign_correctness = (torch.sign(pred_value) == torch.sign(discounted_rewards)).float().where(loss_mask, torch.tensor(0.0)).sum()\n",
    "\n",
    "            total_losses[0] += reconstruction_loss.item()\n",
    "            total_losses[1] += reward_loss.item()\n",
    "            total_losses[2] += value_loss.item()\n",
    "            total_losses[3] += sign_correctness.item()\n",
    "            total_losses[4] += loss_mask.sum()\n",
    "            bar.set_description(f\"Val loss: {total_losses[0] / total_losses[-1]:.6f}, {total_losses[1] / total_losses[-1]:.6f}, {total_losses[2] / total_losses[-1]:.4f}, {total_losses[3] / total_losses[-1]:.4f}\")\n",
    "    # results[model_name].setdefault(\"val_loss\", []).append(total_loss / len(val_loader))\n",
    "\n",
    "    torch.save(model.state_dict(), f\"data/transformer_embedding_model/testing.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "2ee912a5-1ec8-4431-99ef-de9c893d6428",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********Model 0***********\n",
      "Creating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16572/16572 [00:13<00:00, 1199.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created with 487 batches\n",
      "Epoch 1 train loss: 1231.927652\n",
      "Val loss: 942.724365, 0.430980, 0.2891, 0.8725\n",
      "Epoch 2 train loss: 884.420861\n",
      "Val loss: 834.567017, 0.425870, 0.2536, 0.8772\n",
      "Epoch 3 train loss: 807.577553\n",
      "Val loss: 802.419678, 0.423951, 0.2447, 0.8765\n",
      "Epoch 4 train loss: 773.004471\n",
      "Val loss: 774.063538, 0.422593, 0.2352, 0.8815\n",
      "Epoch 5 train loss: 744.405519\n",
      "Val loss: 757.965515, 0.420851, 0.2310, 0.8828\n",
      "Epoch 6 train loss: 728.699241\n",
      "Val loss: 756.250732, 0.418509, 0.2251, 0.8840\n",
      "Epoch 7 train loss: 713.854811\n",
      "Val loss: 746.668884, 0.418598, 0.2254, 0.8833\n",
      "Epoch 8 train loss: 705.445579\n",
      "Val loss: 734.741150, 0.418155, 0.2207, 0.8846\n",
      "Epoch 9 train loss: 697.616737\n",
      "Val loss: 728.091003, 0.417118, 0.2190, 0.8849\n",
      "Epoch 10 train loss: 689.520319\n",
      "Val loss: 726.539978, 0.416121, 0.2196, 0.8842\n",
      "Epoch 11 train loss: 682.635012\n",
      "Val loss: 723.441650, 0.415511, 0.2183, 0.8851\n",
      "Epoch 12 train loss: 676.401432\n",
      "Val loss: 718.623169, 0.415027, 0.2210, 0.8839\n",
      "Epoch 13 train loss: 671.887366\n",
      "Val loss: 725.913940, 0.414115, 0.2175, 0.8858\n",
      "Epoch 14 train loss: 668.970296\n",
      "Val loss: 721.757751, 0.413640, 0.2178, 0.8864\n",
      "Epoch 15 train loss: 664.528839\n",
      "Val loss: 715.254028, 0.413530, 0.2180, 0.8838\n",
      "Epoch 16 train loss: 662.967809\n",
      "Val loss: 718.676941, 0.413487, 0.2163, 0.8847\n",
      "Epoch 17 train loss: 658.541727\n",
      "Val loss: 713.661011, 0.412498, 0.2160, 0.8855\n",
      "Epoch 18 train loss: 657.088838\n",
      "Val loss: 710.298462, 0.412051, 0.2162, 0.8858\n",
      "Epoch 19 train loss: 654.582552\n",
      "Val loss: 705.775635, 0.411241, 0.2148, 0.8843\n",
      "Epoch 20 train loss: 653.577344\n",
      "Val loss: 707.180237, 0.410234, 0.2147, 0.8848\n",
      "Epoch 21 train loss: 651.929534\n",
      "Val loss: 700.160034, 0.410097, 0.2138, 0.8859\n",
      "Epoch 22 train loss: 649.634194\n",
      "Val loss: 711.648071, 0.409409, 0.2145, 0.8851\n",
      "Epoch 23 train loss: 648.086120\n",
      "Val loss: 699.640198, 0.408645, 0.2183, 0.8846\n",
      "Epoch 24 train loss: 647.531997\n",
      "Val loss: 698.986633, 0.407692, 0.2147, 0.8865\n",
      "Epoch 25 train loss: 645.377353\n",
      "Val loss: 697.369568, 0.407785, 0.2138, 0.8861\n",
      "Epoch 26 train loss: 643.779528\n",
      "Val loss: 705.135986, 0.407168, 0.2135, 0.8864\n",
      "Epoch 27 train loss: 642.033972\n",
      "Val loss: 706.219360, 0.406596, 0.2137, 0.8852\n",
      "Epoch 28 train loss: 642.320298\n",
      "Val loss: 706.808167, 0.406372, 0.2133, 0.8860\n",
      "Epoch 29 train loss: 641.881620\n",
      "Val loss: 693.512573, 0.405873, 0.2139, 0.8852\n",
      "Epoch 30 train loss: 641.043744\n",
      "Val loss: 704.056946, 0.405164, 0.2135, 0.8834\n",
      "Epoch 31 train loss: 639.037883\n",
      "Val loss: 702.348267, 0.405057, 0.2147, 0.8838\n",
      "Epoch 32 train loss: 639.128654\n",
      "Val loss: 704.096680, 0.404495, 0.2130, 0.8851\n",
      "Epoch 33 train loss: 637.487906\n",
      "Val loss: 705.256897, 0.404173, 0.2130, 0.8836\n",
      "Epoch 34 train loss: 636.696704\n",
      "Val loss: 693.682556, 0.403639, 0.2144, 0.8852\n",
      "Epoch 35 train loss: 636.512213\n",
      "Val loss: 699.426880, 0.402666, 0.2133, 0.8851\n",
      "Epoch 36 train loss: 637.196403\n",
      "Val loss: 702.455505, 0.402687, 0.2121, 0.8853\n",
      "Epoch 37 train loss: 634.802312\n",
      "Val loss: 698.134277, 0.402352, 0.2133, 0.8869\n",
      "Epoch 38 train loss: 634.262883\n",
      "Val loss: 697.067078, 0.402052, 0.2145, 0.8845\n",
      "Epoch 39 train loss: 632.639039\n",
      "Val loss: 695.712646, 0.401945, 0.2125, 0.8856\n",
      "Early stop.\n",
      "*********Model 1***********\n",
      "Creating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16572/16572 [00:14<00:00, 1117.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created with 489 batches\n",
      "Epoch 1 train loss: 1244.029717\n",
      "Val loss: 936.490662, 0.444924, 0.2617, 0.8813\n",
      "Epoch 2 train loss: 885.044744\n",
      "Val loss: 836.641541, 0.437809, 0.2495, 0.8812\n",
      "Epoch 3 train loss: 806.284032\n",
      "Val loss: 796.875854, 0.434342, 0.2472, 0.8840\n",
      "Epoch 4 train loss: 769.207253\n",
      "Val loss: 776.659607, 0.429822, 0.2423, 0.8830\n",
      "Epoch 5 train loss: 744.660256\n",
      "Val loss: 763.927307, 0.426794, 0.2406, 0.8846\n",
      "Epoch 6 train loss: 726.879946\n",
      "Val loss: 753.754822, 0.423657, 0.2387, 0.8847\n",
      "Epoch 7 train loss: 715.707826\n",
      "Val loss: 744.443359, 0.421475, 0.2355, 0.8848\n",
      "Epoch 8 train loss: 704.725572\n",
      "Val loss: 739.985596, 0.420542, 0.2343, 0.8801\n",
      "Epoch 9 train loss: 696.734270\n",
      "Val loss: 734.474243, 0.419250, 0.2285, 0.8837\n",
      "Epoch 10 train loss: 689.750992\n",
      "Val loss: 732.811951, 0.417771, 0.2286, 0.8837\n",
      "Epoch 11 train loss: 683.127233\n",
      "Val loss: 723.094482, 0.416414, 0.2275, 0.8838\n",
      "Epoch 12 train loss: 678.664109\n",
      "Val loss: 712.180969, 0.415407, 0.2289, 0.8843\n",
      "Epoch 13 train loss: 673.010329\n",
      "Val loss: 714.202209, 0.414477, 0.2277, 0.8834\n",
      "Epoch 14 train loss: 669.103880\n",
      "Val loss: 712.517456, 0.413326, 0.2225, 0.8851\n",
      "Epoch 15 train loss: 665.732858\n",
      "Val loss: 710.339172, 0.412836, 0.2228, 0.8841\n",
      "Epoch 16 train loss: 663.654901\n",
      "Val loss: 704.331848, 0.411944, 0.2224, 0.8840\n",
      "Epoch 17 train loss: 660.415857\n",
      "Val loss: 716.486145, 0.411275, 0.2240, 0.8838\n",
      "Epoch 18 train loss: 657.348091\n",
      "Val loss: 713.680908, 0.410813, 0.2215, 0.8832\n",
      "Epoch 19 train loss: 655.429535\n",
      "Val loss: 696.655457, 0.409923, 0.2213, 0.8840\n",
      "Epoch 20 train loss: 653.848047\n",
      "Val loss: 699.383423, 0.409962, 0.2223, 0.8843\n",
      "Epoch 21 train loss: 652.706592\n",
      "Val loss: 702.003357, 0.409014, 0.2217, 0.8836\n",
      "Epoch 22 train loss: 650.217126\n",
      "Val loss: 697.555542, 0.408488, 0.2207, 0.8828\n",
      "Epoch 23 train loss: 649.016399\n",
      "Val loss: 699.301270, 0.407517, 0.2205, 0.8828\n",
      "Epoch 24 train loss: 648.938220\n",
      "Val loss: 696.933960, 0.407279, 0.2216, 0.8833\n",
      "Epoch 25 train loss: 646.170401\n",
      "Val loss: 694.495544, 0.407573, 0.2199, 0.8818\n",
      "Epoch 26 train loss: 645.383443\n",
      "Val loss: 696.272156, 0.406740, 0.2194, 0.8835\n",
      "Epoch 27 train loss: 644.046424\n",
      "Val loss: 697.613220, 0.405940, 0.2203, 0.8829\n",
      "Epoch 28 train loss: 642.752671\n",
      "Val loss: 691.224487, 0.405619, 0.2218, 0.8838\n",
      "Epoch 29 train loss: 641.132246\n",
      "Val loss: 687.426880, 0.405067, 0.2204, 0.8833\n",
      "Epoch 30 train loss: 640.091409\n",
      "Val loss: 687.947632, 0.404465, 0.2187, 0.8826\n",
      "Epoch 31 train loss: 640.884488\n",
      "Val loss: 680.868896, 0.404116, 0.2209, 0.8845\n",
      "Epoch 32 train loss: 638.779175\n",
      "Val loss: 683.146912, 0.403932, 0.2182, 0.8841\n",
      "Epoch 33 train loss: 637.977043\n",
      "Val loss: 686.613342, 0.403434, 0.2187, 0.8838\n",
      "Epoch 34 train loss: 636.912246\n",
      "Val loss: 690.273926, 0.402615, 0.2183, 0.8854\n",
      "Epoch 35 train loss: 636.829355\n",
      "Val loss: 686.563477, 0.402954, 0.2188, 0.8857\n",
      "Epoch 36 train loss: 636.298059\n",
      "Val loss: 691.223206, 0.402450, 0.2186, 0.8841\n",
      "Epoch 37 train loss: 634.937807\n",
      "Val loss: 688.128784, 0.402117, 0.2190, 0.8836\n",
      "Epoch 38 train loss: 634.607334\n",
      "Val loss: 687.998352, 0.401852, 0.2223, 0.8824\n",
      "Epoch 39 train loss: 634.264108\n",
      "Val loss: 688.872681, 0.401768, 0.2175, 0.8840\n",
      "Epoch 40 train loss: 632.139978\n",
      "Val loss: 688.730469, 0.401247, 0.2237, 0.8796\n",
      "Epoch 41 train loss: 633.536484\n",
      "Val loss: 688.758301, 0.400962, 0.2205, 0.8818\n",
      "Early stop.\n",
      "*********Model 2***********\n",
      "Creating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16572/16572 [00:14<00:00, 1159.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created with 489 batches\n",
      "Epoch 1 train loss: 1231.846100\n",
      "Val loss: 946.540100, 0.439008, 0.2646, 0.8756\n",
      "Epoch 2 train loss: 887.137159\n",
      "Val loss: 839.857361, 0.429050, 0.2532, 0.8782\n",
      "Epoch 3 train loss: 807.388083\n",
      "Val loss: 794.780212, 0.423364, 0.2435, 0.8768\n",
      "Epoch 4 train loss: 768.970694\n",
      "Val loss: 776.808533, 0.418495, 0.2358, 0.8772\n",
      "Epoch 5 train loss: 745.262928\n",
      "Val loss: 757.960449, 0.417203, 0.2332, 0.8784\n",
      "Epoch 6 train loss: 730.075047\n",
      "Val loss: 753.169434, 0.415243, 0.2294, 0.8804\n",
      "Epoch 7 train loss: 716.198208\n",
      "Val loss: 743.283936, 0.412799, 0.2284, 0.8798\n",
      "Epoch 8 train loss: 704.431474\n",
      "Val loss: 733.651245, 0.412851, 0.2320, 0.8779\n",
      "Epoch 9 train loss: 696.671672\n",
      "Val loss: 730.705872, 0.411148, 0.2275, 0.8807\n",
      "Epoch 10 train loss: 689.946026\n",
      "Val loss: 724.425049, 0.410250, 0.2253, 0.8805\n",
      "Epoch 11 train loss: 683.514124\n",
      "Val loss: 718.949890, 0.410040, 0.2245, 0.8796\n",
      "Epoch 12 train loss: 678.427255\n",
      "Val loss: 718.023560, 0.409313, 0.2260, 0.8797\n",
      "Epoch 13 train loss: 676.366377\n",
      "Val loss: 707.964417, 0.408778, 0.2248, 0.8811\n",
      "Epoch 14 train loss: 670.137605\n",
      "Val loss: 714.173889, 0.408044, 0.2255, 0.8777\n",
      "Epoch 15 train loss: 666.895030\n",
      "Val loss: 707.807312, 0.407823, 0.2236, 0.8809\n",
      "Epoch 16 train loss: 663.512149\n",
      "Val loss: 707.933105, 0.407185, 0.2216, 0.8818\n",
      "Epoch 17 train loss: 662.056451\n",
      "Val loss: 704.140869, 0.407068, 0.2240, 0.8812\n",
      "Epoch 18 train loss: 659.362412\n",
      "Val loss: 704.625244, 0.406579, 0.2219, 0.8814\n",
      "Epoch 19 train loss: 657.282178\n",
      "Val loss: 706.150513, 0.406370, 0.2218, 0.8812\n",
      "Epoch 20 train loss: 653.904911\n",
      "Val loss: 706.474854, 0.405375, 0.2261, 0.8798\n",
      "Epoch 21 train loss: 653.578294\n",
      "Val loss: 701.969177, 0.405085, 0.2211, 0.8815\n",
      "Epoch 22 train loss: 651.221641\n",
      "Val loss: 698.041077, 0.404821, 0.2200, 0.8812\n",
      "Epoch 23 train loss: 649.027474\n",
      "Val loss: 698.640442, 0.404670, 0.2204, 0.8830\n",
      "Epoch 24 train loss: 647.899867\n",
      "Val loss: 694.128967, 0.404541, 0.2199, 0.8804\n",
      "Epoch 25 train loss: 646.077545\n",
      "Val loss: 694.985535, 0.403971, 0.2225, 0.8812\n",
      "Epoch 26 train loss: 645.351926\n",
      "Val loss: 702.683472, 0.403972, 0.2192, 0.8818\n",
      "Epoch 27 train loss: 643.691293\n",
      "Val loss: 694.039001, 0.403375, 0.2195, 0.8820\n",
      "Epoch 28 train loss: 642.536406\n",
      "Val loss: 695.175842, 0.403176, 0.2212, 0.8821\n",
      "Epoch 29 train loss: 641.949521\n",
      "Val loss: 690.527283, 0.402976, 0.2196, 0.8822\n",
      "Epoch 30 train loss: 641.626714\n",
      "Val loss: 698.153931, 0.402302, 0.2175, 0.8823\n",
      "Epoch 31 train loss: 640.764560\n",
      "Val loss: 688.867371, 0.401718, 0.2196, 0.8834\n",
      "Epoch 32 train loss: 639.966912\n",
      "Val loss: 696.818909, 0.401583, 0.2181, 0.8827\n",
      "Epoch 33 train loss: 638.266361\n",
      "Val loss: 689.110474, 0.402309, 0.2183, 0.8825\n",
      "Epoch 34 train loss: 639.588050\n",
      "Val loss: 687.904968, 0.401194, 0.2193, 0.8815\n",
      "Epoch 35 train loss: 637.040579\n",
      "Val loss: 692.402832, 0.401048, 0.2184, 0.8810\n",
      "Epoch 36 train loss: 637.256797\n",
      "Val loss: 688.039673, 0.400765, 0.2187, 0.8807\n",
      "Epoch 37 train loss: 636.770232\n",
      "Val loss: 692.406006, 0.400628, 0.2180, 0.8827\n",
      "Epoch 38 train loss: 635.203514\n",
      "Val loss: 692.138184, 0.400684, 0.2175, 0.8826\n",
      "Epoch 39 train loss: 634.453239\n",
      "Val loss: 687.582214, 0.399736, 0.2165, 0.8838\n",
      "Epoch 40 train loss: 634.356718\n",
      "Val loss: 685.020447, 0.399846, 0.2167, 0.8829\n",
      "Epoch 41 train loss: 632.086728\n",
      "Val loss: 685.369141, 0.399667, 0.2188, 0.8819\n",
      "Epoch 42 train loss: 633.291245\n",
      "Val loss: 691.007812, 0.399463, 0.2175, 0.8827\n",
      "Epoch 43 train loss: 633.046564\n",
      "Val loss: 691.829956, 0.399148, 0.2171, 0.8833\n",
      "Epoch 44 train loss: 631.966415\n",
      "Val loss: 688.657104, 0.399267, 0.2184, 0.8824\n",
      "Epoch 45 train loss: 631.468744\n",
      "Val loss: 686.950623, 0.398875, 0.2166, 0.8827\n",
      "Epoch 46 train loss: 631.195924\n",
      "Val loss: 684.493591, 0.398669, 0.2163, 0.8824\n",
      "Epoch 47 train loss: 629.613166\n",
      "Val loss: 688.948853, 0.398508, 0.2174, 0.8821\n",
      "Epoch 48 train loss: 630.342841\n",
      "Val loss: 682.045044, 0.398408, 0.2171, 0.8830\n",
      "Epoch 49 train loss: 629.461692\n",
      "Val loss: 689.884277, 0.398203, 0.2156, 0.8839\n",
      "Epoch 50 train loss: 629.222710\n",
      "Val loss: 686.275635, 0.397480, 0.2169, 0.8838\n",
      "Epoch 51 train loss: 628.774456\n",
      "Val loss: 682.043701, 0.397650, 0.2143, 0.8849\n",
      "Epoch 52 train loss: 628.517905\n",
      "Val loss: 687.717285, 0.397336, 0.2162, 0.8838\n",
      "Epoch 53 train loss: 627.309601\n",
      "Val loss: 687.408875, 0.397376, 0.2174, 0.8845\n",
      "Epoch 54 train loss: 627.958641\n",
      "Val loss: 683.076233, 0.396991, 0.2171, 0.8838\n",
      "Epoch 55 train loss: 627.570654\n",
      "Val loss: 686.349182, 0.396744, 0.2159, 0.8838\n",
      "Epoch 56 train loss: 627.000970\n",
      "Val loss: 687.190430, 0.396659, 0.2168, 0.8829\n",
      "Epoch 57 train loss: 625.818617\n",
      "Val loss: 687.795044, 0.396517, 0.2171, 0.8831\n",
      "Epoch 58 train loss: 625.290180\n",
      "Val loss: 681.869263, 0.396108, 0.2156, 0.8832\n",
      "Epoch 59 train loss: 626.946985\n",
      "Val loss: 680.185852, 0.395969, 0.2141, 0.8848\n",
      "Epoch 60 train loss: 625.741067\n",
      "Val loss: 683.104126, 0.396231, 0.2170, 0.8839\n",
      "Epoch 61 train loss: 626.116306\n",
      "Val loss: 681.901428, 0.395902, 0.2157, 0.8834\n",
      "Epoch 62 train loss: 625.240203\n",
      "Val loss: 683.026245, 0.395879, 0.2163, 0.8831\n",
      "Epoch 63 train loss: 624.546457\n",
      "Val loss: 684.216858, 0.395340, 0.2209, 0.8809\n",
      "Epoch 64 train loss: 624.196299\n",
      "Val loss: 685.263306, 0.395374, 0.2163, 0.8838\n",
      "Epoch 65 train loss: 624.412938\n",
      "Val loss: 686.100769, 0.395130, 0.2175, 0.8840\n",
      "Epoch 66 train loss: 623.657441\n",
      "Val loss: 681.788147, 0.395212, 0.2161, 0.8827\n",
      "Epoch 67 train loss: 623.511462\n",
      "Val loss: 689.224060, 0.395182, 0.2161, 0.8832\n",
      "Epoch 68 train loss: 622.936920\n",
      "Val loss: 684.831848, 0.394726, 0.2168, 0.8836\n",
      "Epoch 69 train loss: 622.530155\n",
      "Val loss: 687.266174, 0.394534, 0.2160, 0.8836\n",
      "Early stop.\n",
      "*********Model 3***********\n",
      "Creating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16572/16572 [00:13<00:00, 1220.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created with 489 batches\n",
      "Epoch 1 train loss: 1228.688034\n",
      "Val loss: 950.660645, 0.431093, 0.2787, 0.8785\n",
      "Epoch 2 train loss: 879.784108\n",
      "Val loss: 837.733154, 0.422976, 0.2418, 0.8819\n",
      "Epoch 3 train loss: 802.846726\n",
      "Val loss: 797.587402, 0.420357, 0.2372, 0.8851\n",
      "Epoch 4 train loss: 764.591637\n",
      "Val loss: 777.895081, 0.419531, 0.2297, 0.8822\n",
      "Epoch 5 train loss: 738.964708\n",
      "Val loss: 762.597473, 0.417472, 0.2271, 0.8826\n",
      "Epoch 6 train loss: 725.240569\n",
      "Val loss: 751.878601, 0.416399, 0.2259, 0.8814\n",
      "Epoch 7 train loss: 713.295888\n",
      "Val loss: 747.578369, 0.414966, 0.2236, 0.8824\n",
      "Epoch 8 train loss: 701.708186\n",
      "Val loss: 736.423767, 0.414340, 0.2230, 0.8838\n",
      "Epoch 9 train loss: 694.001205\n",
      "Val loss: 729.016968, 0.413541, 0.2222, 0.8824\n",
      "Epoch 10 train loss: 687.164799\n",
      "Val loss: 721.435364, 0.412282, 0.2230, 0.8844\n",
      "Epoch 11 train loss: 681.908075\n",
      "Val loss: 722.529480, 0.412006, 0.2199, 0.8840\n",
      "Epoch 12 train loss: 678.117715\n",
      "Val loss: 722.770813, 0.411685, 0.2191, 0.8852\n",
      "Epoch 13 train loss: 670.914011\n",
      "Val loss: 712.582886, 0.410322, 0.2206, 0.8833\n",
      "Epoch 14 train loss: 667.587446\n",
      "Val loss: 718.569397, 0.410167, 0.2192, 0.8856\n",
      "Epoch 15 train loss: 663.603038\n",
      "Val loss: 711.975952, 0.409195, 0.2177, 0.8849\n",
      "Epoch 16 train loss: 660.864994\n",
      "Val loss: 713.408020, 0.409136, 0.2192, 0.8855\n",
      "Epoch 17 train loss: 658.415317\n",
      "Val loss: 705.103821, 0.408215, 0.2155, 0.8845\n",
      "Epoch 18 train loss: 655.522856\n",
      "Val loss: 706.744690, 0.407699, 0.2174, 0.8849\n",
      "Epoch 19 train loss: 653.484319\n",
      "Val loss: 706.686646, 0.407213, 0.2166, 0.8855\n",
      "Epoch 20 train loss: 652.810717\n",
      "Val loss: 700.441711, 0.406404, 0.2166, 0.8851\n",
      "Epoch 21 train loss: 649.378425\n",
      "Val loss: 700.298401, 0.405603, 0.2151, 0.8861\n",
      "Epoch 22 train loss: 648.133603\n",
      "Val loss: 698.679749, 0.405650, 0.2143, 0.8849\n",
      "Epoch 23 train loss: 647.354392\n",
      "Val loss: 693.334229, 0.405173, 0.2160, 0.8843\n",
      "Epoch 24 train loss: 645.931044\n",
      "Val loss: 693.310303, 0.404582, 0.2148, 0.8860\n",
      "Epoch 25 train loss: 644.554656\n",
      "Val loss: 695.705994, 0.404825, 0.2160, 0.8853\n",
      "Epoch 26 train loss: 642.295991\n",
      "Val loss: 695.428284, 0.404020, 0.2158, 0.8859\n",
      "Epoch 27 train loss: 642.053216\n",
      "Val loss: 693.612366, 0.403721, 0.2149, 0.8852\n",
      "Epoch 28 train loss: 641.035429\n",
      "Val loss: 698.083313, 0.403789, 0.2159, 0.8846\n",
      "Epoch 29 train loss: 640.182058\n",
      "Val loss: 692.216248, 0.402979, 0.2146, 0.8852\n",
      "Epoch 30 train loss: 638.376219\n",
      "Val loss: 694.230347, 0.402577, 0.2168, 0.8858\n",
      "Epoch 31 train loss: 638.510011\n",
      "Val loss: 690.535034, 0.402115, 0.2143, 0.8852\n",
      "Epoch 32 train loss: 636.080841\n",
      "Val loss: 689.199036, 0.401802, 0.2158, 0.8843\n",
      "Epoch 33 train loss: 634.389406\n",
      "Val loss: 689.028625, 0.401649, 0.2157, 0.8847\n",
      "Epoch 34 train loss: 635.786507\n",
      "Val loss: 688.183716, 0.401857, 0.2154, 0.8855\n",
      "Epoch 35 train loss: 635.706943\n",
      "Val loss: 689.700073, 0.401166, 0.2145, 0.8852\n",
      "Epoch 36 train loss: 633.281433\n",
      "Val loss: 685.595886, 0.400817, 0.2145, 0.8852\n",
      "Epoch 37 train loss: 632.879380\n",
      "Val loss: 687.179688, 0.400450, 0.2172, 0.8838\n",
      "Epoch 38 train loss: 634.165199\n",
      "Val loss: 687.522461, 0.400238, 0.2146, 0.8860\n",
      "Epoch 39 train loss: 630.885666\n",
      "Val loss: 687.672607, 0.399390, 0.2142, 0.8860\n",
      "Epoch 40 train loss: 631.534856\n",
      "Val loss: 689.426941, 0.399325, 0.2175, 0.8870\n",
      "Epoch 41 train loss: 630.233739\n",
      "Val loss: 685.994324, 0.399029, 0.2136, 0.8848\n",
      "Epoch 42 train loss: 629.534288\n",
      "Val loss: 684.502991, 0.399028, 0.2154, 0.8848\n",
      "Epoch 43 train loss: 630.018059\n",
      "Val loss: 687.127808, 0.398633, 0.2141, 0.8853\n",
      "Epoch 44 train loss: 629.347824\n",
      "Val loss: 688.402039, 0.398085, 0.2134, 0.8852\n",
      "Epoch 45 train loss: 628.288102\n",
      "Val loss: 692.421875, 0.398109, 0.2140, 0.8850\n",
      "Epoch 46 train loss: 628.828494\n",
      "Val loss: 686.085571, 0.398342, 0.2149, 0.8856\n",
      "Epoch 47 train loss: 627.546614\n",
      "Val loss: 691.851318, 0.398075, 0.2173, 0.8859\n",
      "Epoch 48 train loss: 627.246114\n",
      "Val loss: 689.275452, 0.397786, 0.2154, 0.8842\n",
      "Epoch 49 train loss: 625.253511\n",
      "Val loss: 686.586853, 0.397628, 0.2136, 0.8867\n",
      "Epoch 50 train loss: 626.181407\n",
      "Val loss: 683.288696, 0.397118, 0.2150, 0.8860\n",
      "Epoch 51 train loss: 625.798330\n",
      "Val loss: 687.821472, 0.396711, 0.2141, 0.8869\n",
      "Epoch 52 train loss: 624.594315\n",
      "Val loss: 688.040710, 0.396824, 0.2148, 0.8851\n",
      "Epoch 53 train loss: 624.584043\n",
      "Val loss: 687.233276, 0.396568, 0.2145, 0.8852\n",
      "Epoch 54 train loss: 624.521566\n",
      "Val loss: 686.479858, 0.396386, 0.2133, 0.8870\n",
      "Epoch 55 train loss: 623.701520\n",
      "Val loss: 685.652954, 0.396133, 0.2150, 0.8860\n",
      "Epoch 56 train loss: 623.415944\n",
      "Val loss: 679.831482, 0.395934, 0.2141, 0.8858\n",
      "Epoch 57 train loss: 623.341615\n",
      "Val loss: 685.045715, 0.396506, 0.2166, 0.8844\n",
      "Epoch 58 train loss: 623.210885\n",
      "Val loss: 682.040894, 0.395967, 0.2151, 0.8858\n",
      "Epoch 59 train loss: 621.852789\n",
      "Val loss: 679.868530, 0.395862, 0.2166, 0.8856\n",
      "Epoch 60 train loss: 621.739131\n",
      "Val loss: 678.291382, 0.395490, 0.2148, 0.8865\n",
      "Epoch 61 train loss: 622.761204\n",
      "Val loss: 682.212952, 0.395330, 0.2137, 0.8867\n",
      "Epoch 62 train loss: 621.954137\n",
      "Val loss: 684.623474, 0.395068, 0.2132, 0.8862\n",
      "Epoch 63 train loss: 621.140224\n",
      "Val loss: 681.870056, 0.394901, 0.2138, 0.8860\n",
      "Epoch 64 train loss: 622.287709\n",
      "Val loss: 678.476746, 0.394545, 0.2138, 0.8849\n",
      "Epoch 65 train loss: 621.881364\n",
      "Val loss: 681.348694, 0.394664, 0.2134, 0.8852\n",
      "Epoch 66 train loss: 621.206190\n",
      "Val loss: 685.934814, 0.394678, 0.2173, 0.8838\n",
      "Epoch 67 train loss: 621.070638\n",
      "Val loss: 687.102356, 0.394757, 0.2146, 0.8854\n",
      "Epoch 68 train loss: 619.773812\n",
      "Val loss: 683.433228, 0.394416, 0.2175, 0.8849\n",
      "Epoch 69 train loss: 620.226505\n",
      "Val loss: 684.701172, 0.394252, 0.2153, 0.8857\n",
      "Epoch 70 train loss: 620.060106\n",
      "Val loss: 678.598877, 0.394196, 0.2172, 0.8855\n",
      "Early stop.\n",
      "*********Model 4***********\n",
      "Creating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16572/16572 [00:14<00:00, 1149.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created with 489 batches\n",
      "Epoch 1 train loss: 1246.019762\n",
      "Val loss: 942.085754, 0.438817, 0.2729, 0.8725\n",
      "Epoch 2 train loss: 890.259885\n",
      "Val loss: 836.198975, 0.430667, 0.2486, 0.8768\n",
      "Epoch 3 train loss: 813.243970\n",
      "Val loss: 793.101746, 0.426120, 0.2410, 0.8815\n",
      "Epoch 4 train loss: 773.308312\n",
      "Val loss: 769.911560, 0.422030, 0.2341, 0.8776\n",
      "Epoch 5 train loss: 750.243044\n",
      "Val loss: 755.853333, 0.420300, 0.2282, 0.8807\n",
      "Epoch 6 train loss: 733.002710\n",
      "Val loss: 749.527893, 0.417879, 0.2302, 0.8778\n",
      "Epoch 7 train loss: 719.606413\n",
      "Val loss: 734.669250, 0.416167, 0.2263, 0.8784\n",
      "Epoch 8 train loss: 707.412720\n",
      "Val loss: 738.740295, 0.415453, 0.2254, 0.8796\n",
      "Epoch 9 train loss: 698.107445\n",
      "Val loss: 725.739746, 0.413873, 0.2242, 0.8796\n",
      "Epoch 10 train loss: 692.005101\n",
      "Val loss: 718.603394, 0.412482, 0.2232, 0.8814\n",
      "Epoch 11 train loss: 684.775667\n",
      "Val loss: 723.116028, 0.412284, 0.2235, 0.8773\n",
      "Epoch 12 train loss: 678.617981\n",
      "Val loss: 728.660034, 0.410700, 0.2218, 0.8815\n",
      "Epoch 13 train loss: 676.554170\n",
      "Val loss: 720.768555, 0.410034, 0.2210, 0.8824\n",
      "Epoch 14 train loss: 671.012048\n",
      "Val loss: 712.822083, 0.410077, 0.2191, 0.8812\n",
      "Epoch 15 train loss: 667.661770\n",
      "Val loss: 704.181946, 0.408609, 0.2206, 0.8821\n",
      "Epoch 16 train loss: 664.863963\n",
      "Val loss: 710.992493, 0.408558, 0.2204, 0.8798\n",
      "Epoch 17 train loss: 661.431637\n",
      "Val loss: 706.345154, 0.407624, 0.2176, 0.8835\n",
      "Epoch 18 train loss: 658.636616\n",
      "Val loss: 703.819885, 0.407040, 0.2177, 0.8837\n",
      "Epoch 19 train loss: 656.273079\n",
      "Val loss: 706.517700, 0.406420, 0.2202, 0.8799\n",
      "Epoch 20 train loss: 655.340511\n",
      "Val loss: 706.430115, 0.406011, 0.2189, 0.8804\n",
      "Epoch 21 train loss: 651.909145\n",
      "Val loss: 705.008789, 0.405625, 0.2168, 0.8827\n",
      "Epoch 22 train loss: 651.216186\n",
      "Val loss: 705.252991, 0.405005, 0.2243, 0.8763\n",
      "Epoch 23 train loss: 647.499177\n",
      "Val loss: 701.251953, 0.404494, 0.2195, 0.8815\n",
      "Epoch 24 train loss: 647.330685\n",
      "Val loss: 709.666504, 0.404534, 0.2173, 0.8821\n",
      "Epoch 25 train loss: 645.179380\n",
      "Val loss: 700.568726, 0.404291, 0.2224, 0.8771\n",
      "Epoch 26 train loss: 644.205184\n",
      "Val loss: 692.894653, 0.403905, 0.2165, 0.8840\n",
      "Epoch 27 train loss: 643.883843\n",
      "Val loss: 702.084656, 0.404355, 0.2156, 0.8842\n",
      "Epoch 28 train loss: 642.015263\n",
      "Val loss: 700.609131, 0.403713, 0.2164, 0.8848\n",
      "Epoch 29 train loss: 641.250027\n",
      "Val loss: 700.714966, 0.402823, 0.2189, 0.8838\n",
      "Epoch 30 train loss: 640.951374\n",
      "Val loss: 699.119263, 0.403580, 0.2171, 0.8824\n",
      "Epoch 31 train loss: 638.715514\n",
      "Val loss: 697.662476, 0.402546, 0.2162, 0.8837\n",
      "Epoch 32 train loss: 638.803567\n",
      "Val loss: 698.033569, 0.402980, 0.2168, 0.8841\n",
      "Epoch 33 train loss: 637.652335\n",
      "Val loss: 691.835449, 0.401930, 0.2170, 0.8840\n",
      "Epoch 34 train loss: 637.519295\n",
      "Val loss: 698.964050, 0.401751, 0.2162, 0.8842\n",
      "Epoch 35 train loss: 636.968546\n",
      "Val loss: 692.514526, 0.401480, 0.2188, 0.8813\n",
      "Epoch 36 train loss: 635.220720\n",
      "Val loss: 689.427979, 0.401566, 0.2167, 0.8827\n",
      "Epoch 37 train loss: 635.447141\n",
      "Val loss: 695.522278, 0.401199, 0.2156, 0.8840\n",
      "Epoch 38 train loss: 633.137771\n",
      "Val loss: 692.084351, 0.400418, 0.2158, 0.8835\n",
      "Epoch 39 train loss: 634.217948\n",
      "Val loss: 700.898254, 0.400987, 0.2154, 0.8838\n",
      "Epoch 40 train loss: 633.221274\n",
      "Val loss: 697.439514, 0.400658, 0.2138, 0.8843\n",
      "Epoch 41 train loss: 632.371009\n",
      "Val loss: 689.244568, 0.400466, 0.2152, 0.8832\n",
      "Epoch 42 train loss: 631.919847\n",
      "Val loss: 695.774231, 0.400454, 0.2146, 0.8834\n",
      "Epoch 43 train loss: 630.996765\n",
      "Val loss: 693.447327, 0.399958, 0.2148, 0.8839\n",
      "Epoch 44 train loss: 630.352890\n",
      "Val loss: 690.531067, 0.400111, 0.2150, 0.8832\n",
      "Epoch 45 train loss: 629.953781\n",
      "Val loss: 689.868103, 0.399669, 0.2154, 0.8837\n",
      "Epoch 46 train loss: 629.643608\n",
      "Val loss: 687.668823, 0.399413, 0.2194, 0.8817\n",
      "Epoch 47 train loss: 629.559915\n",
      "Val loss: 692.137634, 0.399505, 0.2159, 0.8854\n",
      "Epoch 48 train loss: 628.468479\n",
      "Val loss: 696.382324, 0.398928, 0.2166, 0.8840\n",
      "Epoch 49 train loss: 627.630257\n",
      "Val loss: 688.582886, 0.398698, 0.2153, 0.8846\n",
      "Epoch 50 train loss: 628.256035\n",
      "Val loss: 693.518066, 0.399006, 0.2157, 0.8836\n",
      "Epoch 51 train loss: 627.998526\n",
      "Val loss: 696.945923, 0.398620, 0.2135, 0.8861\n",
      "Epoch 52 train loss: 626.443493\n",
      "Val loss: 693.402405, 0.398139, 0.2153, 0.8826\n",
      "Epoch 53 train loss: 627.146608\n",
      "Val loss: 691.557983, 0.398324, 0.2169, 0.8820\n",
      "Epoch 54 train loss: 626.160388\n",
      "Val loss: 693.385803, 0.398140, 0.2157, 0.8824\n",
      "Epoch 55 train loss: 625.277010\n",
      "Val loss: 688.080383, 0.397643, 0.2167, 0.8838\n",
      "Epoch 56 train loss: 625.378935\n",
      "Val loss: 694.204102, 0.397486, 0.2162, 0.8843\n",
      "Early stop.\n"
     ]
    }
   ],
   "source": [
    "for model_num in range(5):\n",
    "    print(f\"*********Model {model_num}***********\")\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    obs_size = X_train.shape[1]  # embedding dimension\n",
    "    embed_size = 128\n",
    "    nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    nhead = 4  # number of heads in nn.MultiheadAttention\n",
    "    dropout = 0.5  # dropout probability\n",
    "    forward_steps = [1, 2, 4]\n",
    "    model = TransformerModel(obs_size + 2, embed_size, obs_size * len(forward_steps), nhead, nlayers, dropout).to(device)\n",
    "    \n",
    "    lr = 1e-2  # learning rate\n",
    "    reward_lambda = 10.0\n",
    "    value_lambda = 10.0\n",
    "    sign_lambda = 10.0\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "    seq_len = 160\n",
    "    output_scaling_factor = 1.0\n",
    "    grad_norm_clip = 5.0\n",
    "    \n",
    "    resampled_ids = train_ids[np.random.choice(len(train_ids), size=len(train_ids), replace=True)]\n",
    "    print(\"Creating dataset\")\n",
    "    train_stay_ids = dataset[dataset[C_ICUSTAYID].isin(train_ids)][C_ICUSTAYID]\n",
    "    sampled_stay_ids = []\n",
    "    sampled_obs = []\n",
    "    sampled_actions = []\n",
    "    sampled_outcomes = []\n",
    "    for stay_id in tqdm.tqdm(resampled_ids):\n",
    "        mask = train_stay_ids == stay_id\n",
    "        sampled_stay_ids.append(train_stay_ids[mask])\n",
    "        sampled_obs.append(X_train_imputed[mask])\n",
    "        sampled_actions.append(norm_actions_train[mask])\n",
    "        sampled_outcomes.append(y_train[mask])\n",
    "    train_dataset = StateActionDataset(np.concatenate(sampled_stay_ids),\n",
    "                                 np.vstack(sampled_obs),\n",
    "                                 np.vstack(sampled_actions),\n",
    "                                 np.concatenate(sampled_outcomes),\n",
    "                                 replacement_values,\n",
    "                                 max_seq_len,\n",
    "                                 next_step=True,\n",
    "                                 forward_steps=forward_steps,\n",
    "                                 next_step_delta=True)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
    "    print(f\"Created with {len(train_loader)} batches\")\n",
    "\n",
    "    early_stop_threshold = 10\n",
    "    num_nonincreasing = 0\n",
    "    minimum_val_loss = 1e9\n",
    "\n",
    "    # results.setdefault(model_name, {})\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        bar = enumerate(train_loader) #tqdm.tqdm(enumerate(train_loader), total=len(train_loader), ncols=80)\n",
    "        for i, (inputs, outputs, missingness, rewards, discounted_rewards, in_lens) in bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            rewards = rewards.to(device)\n",
    "            discounted_rewards = discounted_rewards.to(device)\n",
    "\n",
    "            pred, pred_rewards, pred_value = model(inputs, src_mask)\n",
    "            # print(pred.shape, outputs.shape, pred_rewards.shape, rewards.shape)\n",
    "            # print(pred.shape, outputs.shape, pred_rewards.shape, rewards.shape, pred_value.shape, discounted_rewards.shape)\n",
    "            loss_mask = torch.arange(inputs.shape[1])[None, :] < in_lens[:, None]\n",
    "\n",
    "            # Idea: weight the examples by how big the change is in each feature\n",
    "            timestep_weights = (outputs ** 2)\n",
    "\n",
    "            l1 = ((reconstruction_criterion(pred, outputs * output_scaling_factor) + sign_lambda * reconstruction_sign_criterion(pred.cdf(0.0), (outputs < 0).float())) * timestep_weights).sum(2)\n",
    "            l2 = reward_criterion(pred_rewards, rewards).sum(2)\n",
    "            l3 = value_criterion(pred_value, discounted_rewards).sum(2)\n",
    "            # print(reconstruction_sign_criterion(pred, outputs * output_scaling_factor))\n",
    "            loss_masked = (l1 + \n",
    "                           reward_lambda * l2 + \n",
    "                           value_lambda * l3\n",
    "                          ).where(loss_mask, torch.tensor(0.0))\n",
    "            loss = loss_masked.sum() / loss_mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            # bar.set_description(f\"Epoch {epoch + 1} train loss: {total_loss / (i + 1):.6f}\")\n",
    "        print(f\"Epoch {epoch + 1} train loss: {total_loss / len(train_loader):.6f}\")\n",
    "        # results[model_name].setdefault(\"train_loss\", []).append(total_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_losses = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "            bar = enumerate(val_loader) # tqdm.tqdm(enumerate(val_loader), total=len(val_loader), ncols=80)\n",
    "            for i, (inputs, outputs, missingness, rewards, discounted_rewards, in_lens) in bar:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = outputs.to(device)\n",
    "                rewards = rewards.to(device)\n",
    "                discounted_rewards = discounted_rewards.to(device)\n",
    "\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "                pred, pred_rewards, pred_value = model(inputs, src_mask)\n",
    "                loss_mask = torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None]\n",
    "\n",
    "                timestep_weights = (outputs ** 2)# .mean(2)\n",
    "                # timestep_weights /= timestep_weights.sum(1, keepdim=True)\n",
    "\n",
    "                reconstruction_loss = ((reconstruction_criterion(pred, outputs * output_scaling_factor) + sign_lambda * reconstruction_sign_criterion(pred.cdf(0.0), (outputs < 0).float())) * timestep_weights).sum(2).where(loss_mask.squeeze(2), torch.tensor(0.0)).sum()\n",
    "                reward_loss = reward_criterion(pred_rewards, rewards).where(loss_mask, torch.tensor(0.0)).sum()\n",
    "                value_loss = value_criterion(pred_value, discounted_rewards).where(loss_mask, torch.tensor(0.0)).sum()\n",
    "                sign_correctness = (torch.sign(pred_value) == torch.sign(discounted_rewards)).float().where(loss_mask, torch.tensor(0.0)).sum()\n",
    "\n",
    "                total_losses[0] += reconstruction_loss.item()\n",
    "                total_losses[1] += reward_loss.item()\n",
    "                total_losses[2] += value_loss.item()\n",
    "                total_losses[3] += sign_correctness.item()\n",
    "                total_losses[4] += loss_mask.sum()\n",
    "                # bar.set_description(f\"Val loss: {total_losses[0] / total_losses[-1]:.6f}, {total_losses[1] / total_losses[-1]:.6f}, {total_losses[2] / total_losses[-1]:.4f}, {total_losses[3] / total_losses[-1]:.4f}\")\n",
    "            print(f\"Val loss: {total_losses[0] / total_losses[-1]:.6f}, {total_losses[1] / total_losses[-1]:.6f}, {total_losses[2] / total_losses[-1]:.4f}, {total_losses[3] / total_losses[-1]:.4f}\")\n",
    "        # results[model_name].setdefault(\"val_loss\", []).append(total_loss / len(val_loader))\n",
    "\n",
    "        if total_losses[0] / total_losses[-1] < minimum_val_loss:\n",
    "            minimum_val_loss = total_losses[0] / total_losses[-1]\n",
    "            num_nonincreasing = 0\n",
    "        else:\n",
    "            num_nonincreasing += 1\n",
    "            if num_nonincreasing == early_stop_threshold:\n",
    "                print(\"Early stop.\")\n",
    "                break\n",
    "        torch.save(model.state_dict(), f\"data/transformer_embedding_model/uncertainty_model_{model_num}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa1d23-db97-4b21-b7a8-53572c45f3eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test out zeroing out all but the first two timesteps\n",
    "k = 50\n",
    "\n",
    "model.eval()\n",
    "survival_predictions = []\n",
    "with torch.no_grad():\n",
    "    total_losses = [0.0, 0.0, 0.0, 0.0]\n",
    "    bar = tqdm.tqdm(enumerate(val_loader), total=len(val_loader), ncols=80)\n",
    "    for i, (inputs, outputs, rewards, discounted_rewards, in_lens) in bar:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        rewards = rewards.to(device)\n",
    "        src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "        \n",
    "        inputs[:,k:,:] = 0\n",
    "        in_lens = torch.from_numpy(np.minimum(in_lens.numpy(), k))\n",
    "        outputs[:,k:,:] = 0\n",
    "\n",
    "        pred, pred_rewards = model(inputs, src_mask)\n",
    "        loss_mask = torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None]\n",
    "        reconstruction_loss = reconstruction_criterion(pred, outputs).where(loss_mask, torch.tensor(0.0)).sum()\n",
    "        reward_loss = reward_criterion(pred_rewards, rewards).where(loss_mask, torch.tensor(0.0)).sum()\n",
    "        sign_correctness = (torch.sign(pred_rewards) == torch.sign(rewards)).float().where(loss_mask, torch.tensor(0.0)).sum()\n",
    "        survival_predictions.append(torch.sign(pred_rewards).numpy())\n",
    "\n",
    "        total_losses[0] += reconstruction_loss.item()\n",
    "        total_losses[1] += reward_loss.item()\n",
    "        total_losses[2] += sign_correctness.item()\n",
    "        total_losses[3] += loss_mask.sum()\n",
    "        bar.set_description(f\"Val loss: {total_losses[0] / total_losses[3]:.6f}, {total_losses[1] / total_losses[3]:.6f}, {total_losses[2] / total_losses[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043c5da-98ca-4c9a-8773-79ec66678ec9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_specs = [\n",
    "    (\"64_one_layer\", (obs_size + 2, 64, obs_size, 1, 1, 0.2)),\n",
    "    (\"64_two_layers\", (obs_size + 2, 64, obs_size, 1, 2, 0.2)),\n",
    "    (\"64_three_layers\", (obs_size + 2, 64, obs_size, 1, 3, 0.2)),\n",
    "    (\"64_2_one_layer\", (obs_size + 2, 64, obs_size, 2, 1, 0.2)),\n",
    "    (\"64_2_two_layers\", (obs_size + 2, 64, obs_size, 2, 2, 0.2)),\n",
    "    (\"64_2_three_layers\", (obs_size + 2, 64, obs_size, 2, 3, 0.2)),\n",
    "    (\"128_2_one_layer\", (obs_size + 2, 128, obs_size, 2, 1, 0.2)),\n",
    "    (\"128_2_two_layers\", (obs_size + 2, 128, obs_size, 2, 2, 0.2)),\n",
    "    (\"128_2_three_layers\", (obs_size + 2, 128, obs_size, 2, 3, 0.2)),\n",
    "    (\"128_4_one_layer\", (obs_size + 2, 128, obs_size, 4, 1, 0.2)),\n",
    "    (\"128_4_two_layers\", (obs_size + 2, 128, obs_size, 4, 2, 0.2)),\n",
    "    (\"128_4_three_layers\", (obs_size + 2, 128, obs_size, 4, 3, 0.2)),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, args in model_specs:\n",
    "    print(\"***********\", model_name, \"*************\")\n",
    "    model = TransformerModel(*args).to(device)\n",
    "    lr = 1e-2  # learning rate\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "    seq_len = 160\n",
    "    \n",
    "    results.setdefault(model_name, {})\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader), ncols=80)\n",
    "        for i, (inputs, outputs, in_lens, out_lens) in bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            pred = model(inputs, src_mask)\n",
    "\n",
    "            loss_mask = torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None]\n",
    "\n",
    "            loss_masked = criterion(pred, outputs).where(loss_mask, torch.tensor(0.0))\n",
    "            loss = loss_masked.sum() / loss_mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            bar.set_description(f\"Train loss: {total_loss / (i + 1):.6f}\")\n",
    "        results[model_name].setdefault(\"train_loss\", []).append(total_loss / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            bar = tqdm.tqdm(enumerate(val_loader), total=len(val_loader), ncols=80)\n",
    "            for i, (inputs, outputs, in_lens, out_lens) in bar:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = outputs.to(device)\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "                pred = model(inputs, src_mask)\n",
    "                loss_mask = torch.arange(inputs.shape[1])[None, :, None] < in_lens[:, None, None]\n",
    "                loss_masked = criterion(pred, outputs).where(loss_mask, torch.tensor(0.0))\n",
    "                loss = loss_masked.sum() / loss_mask.sum()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                bar.set_description(f\"Val loss: {total_loss / (i + 1):.6f}\")\n",
    "        results[model_name].setdefault(\"val_loss\", []).append(total_loss / len(val_loader))\n",
    "        \n",
    "        torch.save(model.state_dict(), f\"data/transformer_embedding_model/{model_name}.pt\")\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a904d0-8c3a-4a34-b3d7-a950edfdc549",
   "metadata": {},
   "source": [
    "# Running the model forward\n",
    "\n",
    "Now that we have a model that takes (prior) states and actions and returns next states and rewards, we can use that model to predict what will happen on trajectories in which the model recommends a different action.\n",
    "\n",
    "Ideally, we would have a way to validate that this approach works on actions other than what the clinician recommended. For instance, we could try the model on eICU to see if it is able to predict the dynamics in those patients as well. \n",
    "\n",
    "We should also verify that the model doesn't unnecessarily modify features that it doesn't need to from timestep to timestep, like age, weight, etc. We could do this by plotting some trajectories according to the model alongside the shifted version of the true labels. We may need to augment the training dataset with corruptions to the inputs, to help make sure that it is able to smooth out and handle these irregularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "1d18eed9-15bf-480b-ada1-aca531b55794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_states_known_actions(stay_ids, observations, actions):\n",
    "    eval_dataset = StateActionDataset(stay_ids,\n",
    "                                      observations,\n",
    "                                      actions,\n",
    "                                      np.zeros(len(actions), dtype=int),\n",
    "                                      replacement_values,\n",
    "                                      max_seq_len,\n",
    "                                      next_step=True,\n",
    "                                      next_step_delta=True)\n",
    "    print(len(stay_ids))\n",
    "    batch_size = 32\n",
    "    eval_loader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)\n",
    "    \n",
    "    model.eval()\n",
    "    predicted_states = []\n",
    "    predicted_state_stds = []\n",
    "    predicted_rewards = []\n",
    "    predicted_values = []\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm.tqdm(enumerate(eval_loader), total=len(eval_loader), ncols=80)\n",
    "        for i, (inputs, outputs, _, rewards, discounted_rewards, in_lens) in bar:\n",
    "            inputs = inputs.to(device)            \n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "            pred, pred_rewards, pred_value = model(inputs, src_mask)\n",
    "            predicted_states += [np.vstack([x[:l], np.zeros(x.shape[1])]) / output_scaling_factor for x, l in zip(pred.loc.cpu().numpy(), in_lens.numpy())]\n",
    "            predicted_state_stds += [np.vstack([x[:l], np.zeros(x.shape[1])]) for x, l in zip(pred.scale.cpu().numpy(), in_lens.numpy())]\n",
    "            predicted_rewards += [np.vstack([x[:l], np.zeros(x.shape[1])]) for x, l in zip(pred_rewards.cpu().numpy(), in_lens.numpy())]\n",
    "            predicted_values += [np.vstack([x[:l], np.zeros(x.shape[1])]) for x, l in zip(pred_value.cpu().numpy(), in_lens.numpy())]\n",
    "            \n",
    "    return np.concatenate(predicted_states), np.concatenate(predicted_state_stds), np.concatenate(predicted_rewards), np.concatenate(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "d883e119-a0cb-4438-8e76-dfce252f8d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 58/58 [00:00<00:00, 92.93it/s]\n"
     ]
    }
   ],
   "source": [
    "val_stay_ids = dataset[dataset[C_ICUSTAYID].isin(val_ids)][C_ICUSTAYID]\n",
    "pred_state, pred_state_std, pred_r, pred_v = predict_next_states_known_actions(val_stay_ids,\n",
    "                             X_val_imputed,\n",
    "                             norm_actions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "0920da41-4bf9-45b2-89ba-2f06defc41ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gender', 0.7301092791411042),\n",
       " ('mechvent', 0.4383148006134969),\n",
       " ('max_dose_vaso', 0.9200536809815951),\n",
       " ('re_admission', 0.07673504601226994),\n",
       " ('age', 0.0495590490797546),\n",
       " ('elixhauser', 0.0888611963190184),\n",
       " ('Height_cm', 0.2875766871165644),\n",
       " ('Weight_kg', 0.20159125766871167),\n",
       " ('GCS', 0.7002971625766872),\n",
       " ('HR', 0.5798983895705522),\n",
       " ('SysBP', 0.5983032975460123),\n",
       " ('MeanBP', 0.6187691717791411),\n",
       " ('DiaBP', 0.6036713957055214),\n",
       " ('RR', 0.6143117331288344),\n",
       " ('Temp_C', 0.5982074386503068),\n",
       " ('FiO2_1', 0.3053105828220859),\n",
       " ('PAPsys', 0.5780770705521472),\n",
       " ('PAPmean', 0.5622124233128835),\n",
       " ('PAPdia', 0.5459643404907976),\n",
       " ('CI', 0.5492235429447853),\n",
       " ('Ionised_Ca', 0.5590011503067485),\n",
       " ('CO2_mEqL', 0.543472009202454),\n",
       " ('Total_protein', 0.5788439417177914),\n",
       " ('Albumin', 0.5323044478527608),\n",
       " ('Troponin', 0.4817868098159509),\n",
       " ('CRP', 0.5742906441717791),\n",
       " ('ACT', 0.5777894938650306),\n",
       " ('Potassium', 0.4655866564417178),\n",
       " ('Sodium', 0.5469229294478528),\n",
       " ('Chloride', 0.5444785276073619),\n",
       " ('Glucose', 0.4983224693251534),\n",
       " ('Magnesium', 0.403038726993865),\n",
       " ('Calcium', 0.5495111196319018),\n",
       " ('Hb', 0.6088957055214724),\n",
       " ('Ht', 0.631614263803681),\n",
       " ('RBC_count', 0.49971242331288346),\n",
       " ('WBC_count', 0.4512557515337423),\n",
       " ('Platelets_count', 0.6915260736196319),\n",
       " ('PTT', 0.30099693251533743),\n",
       " ('PT', 0.5229102760736196),\n",
       " ('Arterial_pH', 0.5455329754601227),\n",
       " ('paO2', 0.49003067484662577),\n",
       " ('paCO2', 0.5203700153374233),\n",
       " ('Arterial_BE', 0.5647526840490797),\n",
       " ('HCO3', 0.5212806748466258),\n",
       " ('ETCO2', 0.5563650306748467),\n",
       " ('SvO2', 0.6047258435582822),\n",
       " ('Arterial_lactate', 0.5005751533742331),\n",
       " ('SOFA', 0.5318251533742331),\n",
       " ('SIRS', 0.5794190950920245),\n",
       " ('SpO2', 0.635832055214724),\n",
       " ('BUN', 0.5801380368098159),\n",
       " ('Creatinine', 0.5139953987730062),\n",
       " ('SGOT', 0.4959259969325153),\n",
       " ('SGPT', 0.506805981595092),\n",
       " ('Total_bili', 0.5214244631901841),\n",
       " ('Direct_bili', 0.5150019171779141),\n",
       " ('INR', 0.5312020705521472),\n",
       " ('input_total', 0.39153565950920244),\n",
       " ('input_step', 0.6058282208588958),\n",
       " ('output_total', 0.778038726993865),\n",
       " ('output_step', 0.5494631901840491),\n",
       " ('Shock_Index', 0.5943251533742331),\n",
       " ('PaO2_FiO2', 0.5476898006134969),\n",
       " ('cumulated_balance', 0.38151840490797545)]"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(ALL_FEATURE_COLUMNS, ((pred_state[:-1,:X_val_imputed.shape[1]] > 0) == ((X_val_imputed[1:] - X_val_imputed[:-1]) > 0)).mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "9ad98d60-d00d-4490-956a-ae8ca3a5be08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x540 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_example = np.random.choice(val_stay_ids)\n",
    "example_indexes = val_stay_ids == val_example\n",
    "delta = 1\n",
    "offset = 0 # X_val_imputed.shape[1] * 2\n",
    "\n",
    "true_states = X_val_imputed[example_indexes]\n",
    "pred_states = pred_state[example_indexes,offset:]\n",
    "pred_state_stds = pred_state_std[example_indexes,offset:]\n",
    "\n",
    "feature_of_interest = C_MEANBP\n",
    "\n",
    "plt.figure(figsize=(5, 3), dpi=180)\n",
    "plt.subplot(211)\n",
    "plt.plot(true_states[delta:, ALL_FEATURE_COLUMNS.index(feature_of_interest)] - true_states[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "# plt.plot(true_states[:-1, ALL_FEATURE_COLUMNS.index(feature_of_interest)] + pred_states[:-1, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "plt.plot(pred_states[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "plt.fill_between(np.arange(len(pred_states) - delta), \n",
    "                pred_states[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)] - 1.96 * pred_state_stds[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)],\n",
    "                pred_states[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)] + 1.96 * pred_state_stds[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)],\n",
    "                alpha=0.2)\n",
    "plt.title(feature_of_interest)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(true_states[delta:, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "plt.plot(true_states[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)] + pred_states[:-delta, ALL_FEATURE_COLUMNS.index(feature_of_interest)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b681d-5227-4f1f-a78d-56cbfc6ff387",
   "metadata": {},
   "source": [
    "I think the model is learning to just spit back out the current state!\n",
    "\n",
    "The transformer model does do a good job of predicting the fluid dosages of the clinicians... oh, that's because that data is included in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934904c-c3c3-4495-9eda-65964c0f4416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
